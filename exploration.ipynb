{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41982808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install python-dotenv\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install google-api-python-client\n",
    "# !pip install mysql-connector-python\n",
    "# !pip install sqlalchemy\n",
    "# !pip install wordcloud\n",
    "# !pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4344b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from googleapiclient.discovery import build\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7c593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get YouTube API key from .env \n",
    "youtube_api_key = os.getenv(\"youtube_api_key\")\n",
    "\n",
    "# Get local MySQL server username from .env\n",
    "mysql_user = os.getenv(\"mysql_user\")\n",
    "# Get local MySQL server password from .env\n",
    "mysql_password = os.getenv(\"mysql_password\")\n",
    "\n",
    "# Get AWS MySQL server username from .env\n",
    "aws_mysql_user = os.getenv(\"aws_mysql_user\")\n",
    "# Get AWS MySQL server password from .env\n",
    "aws_mysql_password = os.getenv(\"aws_mysql_password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83362ef",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf5253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the YouTube service object\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=youtube_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46295f8d",
   "metadata": {},
   "source": [
    "## Channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b01556f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>views</th>\n",
       "      <th>videos</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>thumbnail_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>36999411</td>\n",
       "      <td>312</td>\n",
       "      <td>822000</td>\n",
       "      <td>https://yt3.ggpht.com/ytc/AIdro_l9wLnClpLKJeVm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>22581819</td>\n",
       "      <td>158</td>\n",
       "      <td>454000</td>\n",
       "      <td>https://yt3.ggpht.com/ytc/AIdro_my6YXWfudW8qM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>8276248</td>\n",
       "      <td>88</td>\n",
       "      <td>244000</td>\n",
       "      <td>https://yt3.ggpht.com/s3HLl-uzqEaqww2tkWKgjLFf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id           channel_name     views  videos  \\\n",
       "0  UC7cs8q-gJRlGwj4A8OmCmXg       Alex The Analyst  36999411     312   \n",
       "1  UCLLw7jmFsvfIVaUFsLs8mlQ          Luke Barousse  22581819     158   \n",
       "2  UCJQJAI7IjbLcpsjWdSzYz0Q  Thu Vu data analytics   8276248      88   \n",
       "\n",
       "   subscribers                                      thumbnail_url  \n",
       "0       822000  https://yt3.ggpht.com/ytc/AIdro_l9wLnClpLKJeVm...  \n",
       "1       454000  https://yt3.ggpht.com/ytc/AIdro_my6YXWfudW8qM_...  \n",
       "2       244000  https://yt3.ggpht.com/s3HLl-uzqEaqww2tkWKgjLFf...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select channels\n",
    "channel_names = [\"AlexTheAnalyst\", \"LukeBarousse\", \"Thuvu5\"]\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each channel\n",
    "channels_ls = []\n",
    "\n",
    "# Initialize an empty list to store uploads playlist IDs of all channels\n",
    "uploads_playlist_ids = []\n",
    "\n",
    "# Loop through each channel\n",
    "for channel_name in channel_names:\n",
    "    # Get channel data using the YouTube Channels API\n",
    "    # Note: Uses 1 out of 10.000 units from the daily usage limit \n",
    "    channel_data = youtube.channels().list(part=\"statistics,snippet,contentDetails\", forHandle=channel_name).execute()  \n",
    "\n",
    "    # Extract channel data in dictionary format\n",
    "    channel_dict = {\n",
    "        \"channel_id\": channel_data[\"items\"][0][\"id\"],\n",
    "        \"channel_name\": channel_data[\"items\"][0][\"snippet\"][\"title\"],\n",
    "        \"views\": int(channel_data[\"items\"][0][\"statistics\"][\"viewCount\"]),\n",
    "        \"videos\": int(channel_data[\"items\"][0][\"statistics\"][\"videoCount\"]),\n",
    "        \"subscribers\": int(channel_data[\"items\"][0][\"statistics\"][\"subscriberCount\"])\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Try to get channel thumbnail in maximum resolution\n",
    "        channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"maxres\"][\"url\"]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            # If maxres is not available, get high resolution\n",
    "            channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]\n",
    "        except KeyError:\n",
    "            # If high resolution is not available, get default resolution\n",
    "            channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "    \n",
    "    # Append channel data in dictionary format to the list\n",
    "    channels_ls.append(channel_dict)\n",
    "    \n",
    "    # Append uploads playlist ID to the list \n",
    "    uploads_playlist_ids.append(channel_data[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"])\n",
    "\n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "channel_df = pd.DataFrame(channels_ls) \n",
    "channel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de124b",
   "metadata": {},
   "source": [
    "## Video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e34385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_description</th>\n",
       "      <th>published_at</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>thumbnail_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZYps6TmBkWk</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Azure Account Setup + $200 Free Credits | Azur...</td>\n",
       "      <td>In this lesson we will be setting up and walki...</td>\n",
       "      <td>2024-07-16 12:00:38</td>\n",
       "      <td>PT6M37S</td>\n",
       "      <td>4056</td>\n",
       "      <td>201</td>\n",
       "      <td>25</td>\n",
       "      <td>https://i.ytimg.com/vi/ZYps6TmBkWk/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zv1nfZTYpio</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Building a Fully Interactive Web App using Shi...</td>\n",
       "      <td>In this video we are building a Full Shiny App...</td>\n",
       "      <td>2024-07-09 12:01:07</td>\n",
       "      <td>PT59M52S</td>\n",
       "      <td>6106</td>\n",
       "      <td>235</td>\n",
       "      <td>20</td>\n",
       "      <td>https://i.ytimg.com/vi/zv1nfZTYpio/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rn0dSsYXhIE</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Shiny for Python Components and Layouts | Cust...</td>\n",
       "      <td>In this video we look at how we can customize ...</td>\n",
       "      <td>2024-07-02 12:01:00</td>\n",
       "      <td>PT24M8S</td>\n",
       "      <td>3508</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "      <td>https://i.ytimg.com/vi/rn0dSsYXhIE/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>siHou7lObbo</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Shiny for Python Setup and Install | Deploying...</td>\n",
       "      <td>In this video we are going to install Shiny an...</td>\n",
       "      <td>2024-06-25 12:00:53</td>\n",
       "      <td>PT14M24S</td>\n",
       "      <td>6138</td>\n",
       "      <td>222</td>\n",
       "      <td>31</td>\n",
       "      <td>https://i.ytimg.com/vi/siHou7lObbo/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wJiJXD7MVoY</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Is the Economy on the Brink of a Recession? | ...</td>\n",
       "      <td>The Economy isn't looking good and there's a l...</td>\n",
       "      <td>2024-06-18 12:00:06</td>\n",
       "      <td>PT21M19S</td>\n",
       "      <td>11367</td>\n",
       "      <td>693</td>\n",
       "      <td>124</td>\n",
       "      <td>https://i.ytimg.com/vi/wJiJXD7MVoY/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>5LWoJAh-kww</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Data Analyst Skill Stack // How I Became A Dat...</td>\n",
       "      <td>👩🏻‍💻 My laptop and iPad for doing DS/ study 👉 ...</td>\n",
       "      <td>2021-06-16 10:16:47</td>\n",
       "      <td>PT10M35S</td>\n",
       "      <td>33230</td>\n",
       "      <td>1793</td>\n",
       "      <td>70</td>\n",
       "      <td>https://i.ytimg.com/vi/5LWoJAh-kww/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>_RzoHVWKwq4</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Effective visual note-taking on iPad + Downloa...</td>\n",
       "      <td>Hi there! In this video I’m showing you how to...</td>\n",
       "      <td>2021-06-09 06:58:21</td>\n",
       "      <td>PT8M19S</td>\n",
       "      <td>12599</td>\n",
       "      <td>420</td>\n",
       "      <td>15</td>\n",
       "      <td>https://i.ytimg.com/vi/_RzoHVWKwq4/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>hWKLO7GtpiU</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Data scientist is NOT the only SEXY job // All...</td>\n",
       "      <td>Hi there! In this video I explain different da...</td>\n",
       "      <td>2021-06-01 22:51:42</td>\n",
       "      <td>PT14M4S</td>\n",
       "      <td>9041</td>\n",
       "      <td>295</td>\n",
       "      <td>20</td>\n",
       "      <td>https://i.ytimg.com/vi/hWKLO7GtpiU/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>dBZqggW22rs</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>How I take notes on iPad Pro | Notion, Notes, ...</td>\n",
       "      <td>My note-taking system tour in Notion and tips ...</td>\n",
       "      <td>2021-05-16 22:47:12</td>\n",
       "      <td>PT9M7S</td>\n",
       "      <td>12001</td>\n",
       "      <td>281</td>\n",
       "      <td>21</td>\n",
       "      <td>https://i.ytimg.com/vi/dBZqggW22rs/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>How to stay focused and productive online with...</td>\n",
       "      <td>Hello Youtube! This is my first ever Youtube v...</td>\n",
       "      <td>2021-04-30 16:03:53</td>\n",
       "      <td>PT4M34S</td>\n",
       "      <td>5098</td>\n",
       "      <td>176</td>\n",
       "      <td>14</td>\n",
       "      <td>https://i.ytimg.com/vi/QDdqsFCIxIk/maxresdefau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                channel_id  \\\n",
       "0    ZYps6TmBkWk  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "1    zv1nfZTYpio  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "2    rn0dSsYXhIE  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "3    siHou7lObbo  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "4    wJiJXD7MVoY  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "..           ...                       ...   \n",
       "554  5LWoJAh-kww  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "555  _RzoHVWKwq4  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "556  hWKLO7GtpiU  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "557  dBZqggW22rs  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "558  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "\n",
       "                                           video_title  \\\n",
       "0    Azure Account Setup + $200 Free Credits | Azur...   \n",
       "1    Building a Fully Interactive Web App using Shi...   \n",
       "2    Shiny for Python Components and Layouts | Cust...   \n",
       "3    Shiny for Python Setup and Install | Deploying...   \n",
       "4    Is the Economy on the Brink of a Recession? | ...   \n",
       "..                                                 ...   \n",
       "554  Data Analyst Skill Stack // How I Became A Dat...   \n",
       "555  Effective visual note-taking on iPad + Downloa...   \n",
       "556  Data scientist is NOT the only SEXY job // All...   \n",
       "557  How I take notes on iPad Pro | Notion, Notes, ...   \n",
       "558  How to stay focused and productive online with...   \n",
       "\n",
       "                                     video_description        published_at  \\\n",
       "0    In this lesson we will be setting up and walki... 2024-07-16 12:00:38   \n",
       "1    In this video we are building a Full Shiny App... 2024-07-09 12:01:07   \n",
       "2    In this video we look at how we can customize ... 2024-07-02 12:01:00   \n",
       "3    In this video we are going to install Shiny an... 2024-06-25 12:00:53   \n",
       "4    The Economy isn't looking good and there's a l... 2024-06-18 12:00:06   \n",
       "..                                                 ...                 ...   \n",
       "554  👩🏻‍💻 My laptop and iPad for doing DS/ study 👉 ... 2021-06-16 10:16:47   \n",
       "555  Hi there! In this video I’m showing you how to... 2021-06-09 06:58:21   \n",
       "556  Hi there! In this video I explain different da... 2021-06-01 22:51:42   \n",
       "557  My note-taking system tour in Notion and tips ... 2021-05-16 22:47:12   \n",
       "558  Hello Youtube! This is my first ever Youtube v... 2021-04-30 16:03:53   \n",
       "\n",
       "    video_duration  views  likes  comments  \\\n",
       "0          PT6M37S   4056    201        25   \n",
       "1         PT59M52S   6106    235        20   \n",
       "2          PT24M8S   3508    114         7   \n",
       "3         PT14M24S   6138    222        31   \n",
       "4         PT21M19S  11367    693       124   \n",
       "..             ...    ...    ...       ...   \n",
       "554       PT10M35S  33230   1793        70   \n",
       "555        PT8M19S  12599    420        15   \n",
       "556        PT14M4S   9041    295        20   \n",
       "557         PT9M7S  12001    281        21   \n",
       "558        PT4M34S   5098    176        14   \n",
       "\n",
       "                                         thumbnail_url  \n",
       "0    https://i.ytimg.com/vi/ZYps6TmBkWk/maxresdefau...  \n",
       "1    https://i.ytimg.com/vi/zv1nfZTYpio/maxresdefau...  \n",
       "2    https://i.ytimg.com/vi/rn0dSsYXhIE/maxresdefau...  \n",
       "3    https://i.ytimg.com/vi/siHou7lObbo/maxresdefau...  \n",
       "4    https://i.ytimg.com/vi/wJiJXD7MVoY/maxresdefau...  \n",
       "..                                                 ...  \n",
       "554  https://i.ytimg.com/vi/5LWoJAh-kww/maxresdefau...  \n",
       "555  https://i.ytimg.com/vi/_RzoHVWKwq4/maxresdefau...  \n",
       "556  https://i.ytimg.com/vi/hWKLO7GtpiU/maxresdefau...  \n",
       "557  https://i.ytimg.com/vi/dBZqggW22rs/maxresdefau...  \n",
       "558  https://i.ytimg.com/vi/QDdqsFCIxIk/maxresdefau...  \n",
       "\n",
       "[559 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store dictionaries for each video\n",
    "videos_ls = []\n",
    "\n",
    "# Loop through each channel's uploads playlist\n",
    "for uploads_playlist_id in uploads_playlist_ids:\n",
    "    # Initialize next_page_token to None\n",
    "    next_page_token = None\n",
    "\n",
    "    # Loop through each video in the playlist\n",
    "    while True:\n",
    "        # Get playlist data using the YouTube PlaylistItems API \n",
    "        # Note: Each loop uses 1 out of 10.000 units from the daily usage limit (1 unit for 50 videos)\n",
    "        playlist_data = youtube.playlistItems().list(\n",
    "            part=\"snippet\", \n",
    "            playlistId=uploads_playlist_id, \n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        # Initialize an empty list to store video IDs\n",
    "        video_ids = []\n",
    "\n",
    "        # Extract video IDs from the playlist data\n",
    "        video_ids += [video_data[\"snippet\"][\"resourceId\"][\"videoId\"] for video_data in playlist_data[\"items\"]]\n",
    "\n",
    "        # Get video data using the YouTube Videos API \n",
    "        # Note: Uses 1 out of 10.000 units from the daily usage limit (1 unit for 50 videos)\n",
    "        video_data = youtube.videos().list(part=\"statistics,snippet,contentDetails\", id=video_ids).execute()    \n",
    "\n",
    "        # Loop through each video \n",
    "        for video in video_data[\"items\"]:\n",
    "            # Extract video data in dictionary format\n",
    "            video_dict = {\n",
    "                \"video_id\": video[\"id\"],\n",
    "                \"channel_id\": video[\"snippet\"][\"channelId\"],\n",
    "                \"video_title\": video[\"snippet\"][\"title\"],\n",
    "                \"video_description\": video[\"snippet\"][\"description\"],\n",
    "                \"published_at\": datetime.strptime(video[\"snippet\"][\"publishedAt\"], \"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                \"video_duration\": video[\"contentDetails\"][\"duration\"],\n",
    "                \"views\": int(video[\"statistics\"][\"viewCount\"]),\n",
    "                \"likes\": int(video[\"statistics\"][\"likeCount\"]),\n",
    "                \"comments\": int(video[\"statistics\"][\"commentCount\"])\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                # Try to get thumbnail in maximum resolution\n",
    "                video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"maxres\"][\"url\"]\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    # If maxres is not available, get high resolution\n",
    "                    video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]\n",
    "                except KeyError:\n",
    "                    # If high resolution is not available, get default resolution\n",
    "                    video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "\n",
    "            # Append video data in dictionary format to the list\n",
    "            videos_ls.append(video_dict)\n",
    "\n",
    "        # Get the next page token\n",
    "        next_page_token = playlist_data.get(\"nextPageToken\")\n",
    "\n",
    "        # Exit the loop if there are no more pages\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "        \n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "videos_df = pd.DataFrame(videos_ls)    \n",
    "videos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e9e28",
   "metadata": {},
   "source": [
    "## Comments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14367996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get comments for video W_s4c1vLGXM.\n",
      "Failed to get comments for video qfyynHBFOsM.\n",
      "Failed to get comments for video G4syHs3M82E.\n",
      "Failed to get comments for video LJtFgnHGAos.\n",
      "Failed to get comments for video r9imv1z82jQ.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgzSfHTFO8ZWcg_maUF4AaABAg</td>\n",
       "      <td>ZYps6TmBkWk</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>i'm ready</td>\n",
       "      <td>2024-07-22 23:04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugym_vQM6LOs4x1mV5N4AaABAg</td>\n",
       "      <td>ZYps6TmBkWk</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Please help me</td>\n",
       "      <td>2024-07-21 16:04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgwuWMq45Mw5DmWuCkJ4AaABAg</td>\n",
       "      <td>ZYps6TmBkWk</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hey Alex the social  links in your channel des...</td>\n",
       "      <td>2024-07-19 23:44:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugz9XMUa83zfOqZQ17h4AaABAg</td>\n",
       "      <td>ZYps6TmBkWk</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>The future of Binance: an exclusive interview ...</td>\n",
       "      <td>2024-07-19 06:50:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugx5zQmHZ_vs6PPI7Ht4AaABAg</td>\n",
       "      <td>ZYps6TmBkWk</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Thanks Alex! Great series, much needed! Could ...</td>\n",
       "      <td>2024-07-18 23:40:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58222</th>\n",
       "      <td>UgykL4IfQ7CLbONTW5t4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>thank you, please i need you help!!</td>\n",
       "      <td>2022-03-07 11:10:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58223</th>\n",
       "      <td>UgzyWHk3Kx6N3sbElMJ4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Very diff but great inputs from similar topic ...</td>\n",
       "      <td>2022-02-20 00:42:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58224</th>\n",
       "      <td>Ugw1X4GuVl6jdAB8sFJ4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Replying email and control backspace was new f...</td>\n",
       "      <td>2021-08-02 15:15:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58225</th>\n",
       "      <td>UgzDqSm_tOqxIbgclvF4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Valuable insight😇</td>\n",
       "      <td>2021-07-14 10:17:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58226</th>\n",
       "      <td>Ugy9O3Xlo1_2Oqb8G-R4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>good tips for working time at home</td>\n",
       "      <td>2021-05-04 09:26:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58227 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       comment_id     video_id                channel_id  \\\n",
       "0      UgzSfHTFO8ZWcg_maUF4AaABAg  ZYps6TmBkWk  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "1      Ugym_vQM6LOs4x1mV5N4AaABAg  ZYps6TmBkWk  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "2      UgwuWMq45Mw5DmWuCkJ4AaABAg  ZYps6TmBkWk  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "3      Ugz9XMUa83zfOqZQ17h4AaABAg  ZYps6TmBkWk  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "4      Ugx5zQmHZ_vs6PPI7Ht4AaABAg  ZYps6TmBkWk  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "...                           ...          ...                       ...   \n",
       "58222  UgykL4IfQ7CLbONTW5t4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "58223  UgzyWHk3Kx6N3sbElMJ4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "58224  Ugw1X4GuVl6jdAB8sFJ4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "58225  UgzDqSm_tOqxIbgclvF4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "58226  Ugy9O3Xlo1_2Oqb8G-R4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "\n",
       "                                            comment_text        published_at  \n",
       "0                                              i'm ready 2024-07-22 23:04:43  \n",
       "1                                         Please help me 2024-07-21 16:04:03  \n",
       "2      Hey Alex the social  links in your channel des... 2024-07-19 23:44:53  \n",
       "3      The future of Binance: an exclusive interview ... 2024-07-19 06:50:19  \n",
       "4      Thanks Alex! Great series, much needed! Could ... 2024-07-18 23:40:08  \n",
       "...                                                  ...                 ...  \n",
       "58222                thank you, please i need you help!! 2022-03-07 11:10:44  \n",
       "58223  Very diff but great inputs from similar topic ... 2022-02-20 00:42:23  \n",
       "58224  Replying email and control backspace was new f... 2021-08-02 15:15:34  \n",
       "58225                                  Valuable insight😇 2021-07-14 10:17:53  \n",
       "58226                 good tips for working time at home 2021-05-04 09:26:36  \n",
       "\n",
       "[58227 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store comments\n",
    "comments_ls = []\n",
    "\n",
    "# Loop through each video\n",
    "for video_id in videos_df[\"video_id\"].values:\n",
    "    # Initialize next_page_token to None\n",
    "    next_page_token = None\n",
    "\n",
    "    # Loop through data batches of 100 comments \n",
    "    while True:\n",
    "        try:\n",
    "            # Get data from 100 comments using the YouTube CommentThreads API \n",
    "            # Note: Each loop uses 1 out of 10.000 units from the daily usage limit (1 unit for 100 comments)\n",
    "            comments_data = youtube.commentThreads().list(\n",
    "                part=\"snippet\", \n",
    "                videoId=video_id, \n",
    "                maxResults=100,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "        # Handle error if e.g. video comments are disabled\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get comments for video {video_id}.\")\n",
    "\n",
    "        # Loop through each comment\n",
    "        for comment in comments_data[\"items\"]:\n",
    "            # Extract comment data in dictionary format\n",
    "            comment_dict = {\n",
    "                \"comment_id\": comment[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                \"video_id\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"videoId\"],\n",
    "                \"channel_id\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"channelId\"],\n",
    "                \"comment_text\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"],\n",
    "                \"published_at\": datetime.strptime(comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            }\n",
    "            # Append comment data dictionary to the list\n",
    "            comments_ls.append(comment_dict)\n",
    "\n",
    "        # Get the next page token\n",
    "        next_page_token = comments_data.get(\"nextPageToken\")\n",
    "\n",
    "        # Exit the loop if there are no more pages\n",
    "        if next_page_token is None: \n",
    "            break\n",
    "        \n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "comments_df = pd.DataFrame(comments_ls)    \n",
    "comments_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182313c6",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08f384",
   "metadata": {},
   "source": [
    "## Convert video duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f293dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the YouTube video duration from ISO 8601 format (str) to seconds (int)\n",
    "def convert_iso8601_duration(duration):\n",
    "    # Regular expression to match hours, minutes, and seconds\n",
    "    time_extractor = re.compile(r'PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?')\n",
    "    # Extract hours, minutes, and seconds\n",
    "    extracted = time_extractor.match(duration)\n",
    "    if extracted:\n",
    "        hours = int(extracted.group(1)) if extracted.group(1) else 0\n",
    "        minutes = int(extracted.group(2)) if extracted.group(2) else 0\n",
    "        seconds = int(extracted.group(3)) if extracted.group(3) else 0\n",
    "        # Return total seconds\n",
    "        total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "        return total_seconds\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1037c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert video duration in pandas DataFrame\n",
    "videos_df[\"video_duration\"] = videos_df[\"video_duration\"].apply(convert_iso8601_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a313e62",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ced55",
   "metadata": {},
   "source": [
    "## Into local MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    port = 3306,\n",
    "    user = mysql_user,\n",
    "    password = mysql_password,\n",
    "    database = \"youtube_analytics\"\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Drop existing MySQL tables \n",
    "tables_to_drop = [\"comments\", \"videos\", \"channels\"]\n",
    "for table in tables_to_drop:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "        \n",
    "try:\n",
    "    # Create an SQLAlchemy engine for interacting with the MySQL database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{mysql_user}:{mysql_password}@localhost:3306/youtube_analytics\") \n",
    "    \n",
    "    # Load the YouTube channels DataFrame into the MySQL channels table\n",
    "    try:\n",
    "        channel_df.to_sql(\"channels\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Channels data successfully loaded into local MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading channels data:\", e)\n",
    "    \n",
    "    # Load the YouTube videos DataFrame into the MySQL videos table\n",
    "    try:\n",
    "        videos_df.to_sql(\"videos\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Videos data successfully loaded into local MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading videos data:\", e)\n",
    "    \n",
    "    # Load the YouTube comments DataFrame into the MySQL comments table\n",
    "    try:\n",
    "        comments_df.to_sql(\"comments\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Comments data successfully loaded into local MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading comments data:\", e)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print error if exception occurs when connecting to the database \n",
    "    print(\"Error connecting to local MySQL database:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection to free up resources\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b5884",
   "metadata": {},
   "source": [
    "## Into AWS MySQL database\n",
    "Note: Make sure to establish an SSH tunnel via PuTTY to connect to the AWS RDS MySQL server instance through the EC2 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to AWS MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    port = 3308,\n",
    "    user = aws_mysql_user,\n",
    "    password = aws_mysql_password,\n",
    "    database = \"youtube_analytics\"\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Drop existing MySQL tables \n",
    "tables_to_drop = [\"comments\", \"videos\", \"channels\"]\n",
    "for table in tables_to_drop:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "        \n",
    "try:\n",
    "    # Create an SQLAlchemy engine for interacting with the MySQL database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{aws_mysql_user}:{aws_mysql_password}@localhost:3308/youtube_analytics\") \n",
    "    \n",
    "    # Load the YouTube channels DataFrame into the MySQL channels table\n",
    "    try:\n",
    "        channel_df.to_sql(\"channels\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Channels data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading channels data:\", e)\n",
    "    \n",
    "    # Load the YouTube videos DataFrame into the MySQL videos table\n",
    "    try:\n",
    "        videos_df.to_sql(\"videos\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Videos data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading videos data:\", e)\n",
    "    \n",
    "    # Load the YouTube comments DataFrame into the MySQL comments table\n",
    "    try:\n",
    "        comments_df.to_sql(\"comments\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Comments data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading comments data:\", e)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print error if exception occurs when connecting to the database \n",
    "    print(\"Error connecting to AWS MySQL database:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection to free up resources\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28ac4d",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c8eb9-9193-4b4c-b3a9-5a56cc4519fb",
   "metadata": {},
   "source": [
    "To identify the most effective sentiment analysis method for YouTube comments, we will compare three models: VADER, DistilBERT, and RoBERTa. Each will be applied to a dataset of 50 randomly selected comments. VADER employs a rule-based approach, while DistilBERT and RoBERTa are machine learning-based approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d02543-b8d4-428e-a16e-ee04c0fe92a3",
   "metadata": {},
   "source": [
    "## Fetch example comments\n",
    "Fetch 50 random comments from the AWS RDS MySQL comments table.\n",
    "\n",
    "Note: Make sure to establish an SSH tunnel via PuTTY to connect to the AWS RDS MySQL server instance through the EC2 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b139dcc7-63ad-4779-9aba-164d6a7b7f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 random comments successfully fetched from the AWS MySQL database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create an SQLAlchemy engine for interacting with the MySQL database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{aws_mysql_user}:{aws_mysql_password}@localhost:3308/youtube_analytics\") \n",
    "    \n",
    "    # MySQL query to fetch 50 random comments\n",
    "    query = \"SELECT * FROM comments ORDER BY RAND() LIMIT 50\"\n",
    "    \n",
    "    # Execute query to load the comments from the MySQL comments table into a pandas DataFrame\n",
    "    try:\n",
    "        random_comments_df = pd.read_sql(query, engine)\n",
    "        print(\"50 random comments successfully fetched from the AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching random comments from the AWS MySQL database:\", e)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print error if exception occurs when connecting to the database \n",
    "    print(\"Error connecting to AWS MySQL database:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close the database connection\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b20df05c-8ba5-49e7-91e6-42a4fff2438d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgxT6HsOQ2C0pifnQcx4AaABAg</td>\n",
       "      <td>M2ySRYpo9S0</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>One nice thing is that I read you can potentia...</td>\n",
       "      <td>2021-04-06 22:54:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugx_C5utab-eTH5c4Lh4AaABAg</td>\n",
       "      <td>wgRwITQHszU</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>i want to say thank you sir! Alex The Analyst\\...</td>\n",
       "      <td>2024-06-27 06:03:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugxg_fCY_Y0Ah-_JcZh4AaABAg</td>\n",
       "      <td>KRXSJb9ql1Y</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hmmm...  Wonder how I managed to get my commen...</td>\n",
       "      <td>2024-05-14 02:08:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgyToBpiOh4x-u-nLbx4AaABAg</td>\n",
       "      <td>NQSe-SuykJU</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>dude I don't know if you know this, but RP cam...</td>\n",
       "      <td>2023-02-02 00:15:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugy7az9R_be4_xLWeZF4AaABAg</td>\n",
       "      <td>9RRQtNnq3s0</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hi Alex.  Thanks a lot for this video!  One qu...</td>\n",
       "      <td>2021-04-13 11:27:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UgwskNedGDZS5UWiR5R4AaABAg</td>\n",
       "      <td>tpGawyNMRLM</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>I work at fedex and i just saw your play butto...</td>\n",
       "      <td>2023-01-30 05:59:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ugz1VaDlGpYn7PdsNcp4AaABAg</td>\n",
       "      <td>wnapnTAMj68</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>It’s not worth it. But this is a google platfo...</td>\n",
       "      <td>2022-03-17 19:53:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UgyWgwipQBo9nsZ4yTp4AaABAg</td>\n",
       "      <td>dMHWOhgzUhU</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Thanks for your detailed tips 👍</td>\n",
       "      <td>2021-06-10 13:52:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ugz4R5zvS3NFzOLLANF4AaABAg</td>\n",
       "      <td>aJ9Q10v8Nrc</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>This was great!! Has anyone signed up for the ...</td>\n",
       "      <td>2022-05-11 21:39:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ugx-QEAKvdva7l_HGzh4AaABAg</td>\n",
       "      <td>fUpChfNN5Uo</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Additionally you need to have excellent presen...</td>\n",
       "      <td>2021-10-11 06:39:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UgyWHVbiZVknOPk_SJJ4AaABAg</td>\n",
       "      <td>ppsCxnNm-JI</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>This is great. Thanks for clarifying with exam...</td>\n",
       "      <td>2023-11-25 11:30:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ugwlxui0EL9GiH4OzOJ4AaABAg</td>\n",
       "      <td>rGx1QNdYzvs</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>i actually don't know you, but this video prem...</td>\n",
       "      <td>2023-02-07 13:25:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UgxE11N7QqPQZuYlmxt4AaABAg</td>\n",
       "      <td>St48epdRDZw</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>you are amazing 😍</td>\n",
       "      <td>2024-07-22 23:43:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UgwoAep726EuVV67xu94AaABAg</td>\n",
       "      <td>qfyynHBFOsM</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>I've been trying to import it into SSMS v19.3,...</td>\n",
       "      <td>2024-01-23 01:41:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UgxT1U-Ziak11Oi9-i54AaABAg</td>\n",
       "      <td>DXwFsxCtukg</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hi Alex quick question how long do you think w...</td>\n",
       "      <td>2023-01-11 07:06:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UgwNlim3dXjTc_rjNKx4AaABAg</td>\n",
       "      <td>4UltKCnnnTA</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hello all, \\nfor the part where he deleted the...</td>\n",
       "      <td>2024-06-18 11:16:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UgwioeJl36UMJu3HGeJ4AaABAg</td>\n",
       "      <td>QILNlRvJlfQ</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>I have a student version of Tableau, so I was ...</td>\n",
       "      <td>2023-01-21 21:13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UgzaAMSfbC9GMj_B3Bd4AaABAg</td>\n",
       "      <td>EzVIkHQWnhc</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Thank you for sharing this helpful thing. 💙</td>\n",
       "      <td>2023-08-22 04:35:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ugzmba2nOuuX753BY9F4AaABAg</td>\n",
       "      <td>dMHWOhgzUhU</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Do i need to know programming to become data a...</td>\n",
       "      <td>2021-10-18 02:40:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UgwAVqkauXwRBtFvRch4AaABAg</td>\n",
       "      <td>RSlqWnP-Dy8</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>I tried inserting rows but I am coming up with...</td>\n",
       "      <td>2024-03-03 22:18:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UgxYFw4Omh2-VZ_uPoJ4AaABAg</td>\n",
       "      <td>Zcy-ND_4ydQ</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>The main reason is Python would be so long to ...</td>\n",
       "      <td>2022-05-07 20:11:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ugw6_HkS66Cd7gTiWUJ4AaABAg</td>\n",
       "      <td>aLp-6C-p-T0</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Yes true.. That has been my approach...You can...</td>\n",
       "      <td>2021-07-18 19:09:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UgzlNvwaPDuH-LGBffV4AaABAg</td>\n",
       "      <td>qfyynHBFOsM</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hey Alex,\\nI chose to work on BigQuery as SQL....</td>\n",
       "      <td>2021-08-22 18:24:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UgyDIFz35EFbW6oPngJ4AaABAg</td>\n",
       "      <td>_zxPx1PQCqI</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hey Alex, I just wanted to say thank you for a...</td>\n",
       "      <td>2021-08-11 22:07:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UgwXmTGwI7M7dNRuaOp4AaABAg</td>\n",
       "      <td>zOR0-nygfDE</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hi, I have been trying to save the dashboard/w...</td>\n",
       "      <td>2022-01-30 01:12:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ugzzq9JnZy_ZI8XSXtF4AaABAg</td>\n",
       "      <td>QMUZ5HfWMRc</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>AMAZING</td>\n",
       "      <td>2024-05-25 19:37:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>UgwgLsOoP63uwjzVkXF4AaABAg</td>\n",
       "      <td>EE1Y2enHrcU</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>I encountered this error when using free plan ...</td>\n",
       "      <td>2023-03-20 02:21:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UgxO-cPLG4hQGM66rAl4AaABAg</td>\n",
       "      <td>PyYgERKq25I</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Who wants to team up and learn? I'm just start...</td>\n",
       "      <td>2023-08-15 10:54:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UgynJSMRpU8So4x2JsZ4AaABAg</td>\n",
       "      <td>CUa30M_FPhk</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>hey alex even i m trying to get the job in dat...</td>\n",
       "      <td>2021-08-23 18:06:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UgzMXcHpacJh8rFIIkN4AaABAg</td>\n",
       "      <td>9URM1_2S0ho</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>I got us to 669 ;) Awesome Content!</td>\n",
       "      <td>2021-08-19 16:44:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>UgwMuQkFzq6PywxlE-d4AaABAg</td>\n",
       "      <td>C75TROiiEa0</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hi Alex, amazing video, I’ve always been inter...</td>\n",
       "      <td>2023-02-20 14:24:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>UgyxwBZqT9GBUaHAAQ14AaABAg</td>\n",
       "      <td>u3QcbYNUgtU</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>No matter what year it is, it seems Excel is a...</td>\n",
       "      <td>2023-09-22 19:54:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>UgwZyRcTVX-56o9kzgt4AaABAg</td>\n",
       "      <td>XD1ul5fpnGI</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Great videos. Any discount code as of right now?</td>\n",
       "      <td>2024-02-20 07:59:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>UgxuvYTItKz_7IsiLq94AaABAg</td>\n",
       "      <td>HiOtQMcI5wg</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Sir, I am very near to get my first job throug...</td>\n",
       "      <td>2022-04-21 11:51:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UgxHWZLY4sRR3ZdK6uR4AaABAg</td>\n",
       "      <td>pPy3sbeGNjQ</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Excuse the ignorance, what does scraping achieve?</td>\n",
       "      <td>2022-12-21 00:22:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ugyt7KO5FdfYZ3rwUuF4AaABAg</td>\n",
       "      <td>5gf2ntjVGe8</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Good that you clearly pointed out that this co...</td>\n",
       "      <td>2024-03-17 17:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UgxHTBX_qgms7XY_3aV4AaABAg</td>\n",
       "      <td>F1ILGTXKUQM</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Thanks Luke for the video</td>\n",
       "      <td>2024-01-17 05:08:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ugw2ZDUF4qRRMK2rZxx4AaABAg</td>\n",
       "      <td>egtF-C5WIpk</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Why does everyone takes Space grey? And not th...</td>\n",
       "      <td>2022-07-07 21:54:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ugz7b4cg-RCl0VhmodF4AaABAg</td>\n",
       "      <td>xzR4L_XYW3g</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Respected Sir\\r\\nIs the SPSS and AMOS software...</td>\n",
       "      <td>2021-07-22 03:35:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UgzSlFIWxMiSlsal9Kd4AaABAg</td>\n",
       "      <td>qfyynHBFOsM</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>re:grouping by continent @37:14-- even though ...</td>\n",
       "      <td>2022-01-10 02:34:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ugx_NBG2WR20D0_Dcf54AaABAg</td>\n",
       "      <td>HYD8KjPB9F8</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>can you do tutorial of dates in mysql</td>\n",
       "      <td>2023-11-07 13:23:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>UgyI3qISYwNH6MxPZE94AaABAg</td>\n",
       "      <td>U2v76H_B1rs</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>First of all, this is a fabulous collection of...</td>\n",
       "      <td>2022-04-27 04:01:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>UgyF8sb9afUaWSNpb5Z4AaABAg</td>\n",
       "      <td>Z2AachB309o</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Jalapeños Alex! Haha thanks for this other vid...</td>\n",
       "      <td>2022-04-14 10:00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ugx-5WlLIBCpX9zO2ZJ4AaABAg</td>\n",
       "      <td>MfUzKeEKtr8</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>4:33 there he said it.</td>\n",
       "      <td>2023-04-25 21:07:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>UgzLrDRONMSdolPo9tN4AaABAg</td>\n",
       "      <td>tBfIh3VQX2o</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>2022-06-10 21:01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>UgyyhmDjX3ZcaQ2NL3x4AaABAg</td>\n",
       "      <td>JPHS10dt_CY</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Do make similar videos for Quantum Computing i...</td>\n",
       "      <td>2023-02-16 01:02:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>UgyQfEtBtbvgrXY8OS94AaABAg</td>\n",
       "      <td>8dTpNajxaH0</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Thanks a lot!</td>\n",
       "      <td>2024-08-09 13:13:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>UgzieBc9gpnx1igU_IR4AaABAg</td>\n",
       "      <td>uyCXLr7cgrs</td>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Bard will summarize and do other math stuff no...</td>\n",
       "      <td>2023-09-29 18:55:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>UgzPB_FrSjz57bQdyFZ4AaABAg</td>\n",
       "      <td>8SolrjsGqzE</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Avacado</td>\n",
       "      <td>2022-01-19 19:25:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UgxdKlIY9TIhiTzj06B4AaABAg</td>\n",
       "      <td>wnapnTAMj68</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Please stop the soy boy open mouth look. It’s ...</td>\n",
       "      <td>2021-03-25 20:39:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    comment_id     video_id                channel_id  \\\n",
       "0   UgxT6HsOQ2C0pifnQcx4AaABAg  M2ySRYpo9S0  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "1   Ugx_C5utab-eTH5c4Lh4AaABAg  wgRwITQHszU  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "2   Ugxg_fCY_Y0Ah-_JcZh4AaABAg  KRXSJb9ql1Y  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "3   UgyToBpiOh4x-u-nLbx4AaABAg  NQSe-SuykJU  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "4   Ugy7az9R_be4_xLWeZF4AaABAg  9RRQtNnq3s0  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "5   UgwskNedGDZS5UWiR5R4AaABAg  tpGawyNMRLM  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "6   Ugz1VaDlGpYn7PdsNcp4AaABAg  wnapnTAMj68  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "7   UgyWgwipQBo9nsZ4yTp4AaABAg  dMHWOhgzUhU  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "8   Ugz4R5zvS3NFzOLLANF4AaABAg  aJ9Q10v8Nrc  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "9   Ugx-QEAKvdva7l_HGzh4AaABAg  fUpChfNN5Uo  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "10  UgyWHVbiZVknOPk_SJJ4AaABAg  ppsCxnNm-JI  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "11  Ugwlxui0EL9GiH4OzOJ4AaABAg  rGx1QNdYzvs  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "12  UgxE11N7QqPQZuYlmxt4AaABAg  St48epdRDZw  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "13  UgwoAep726EuVV67xu94AaABAg  qfyynHBFOsM  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "14  UgxT1U-Ziak11Oi9-i54AaABAg  DXwFsxCtukg  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "15  UgwNlim3dXjTc_rjNKx4AaABAg  4UltKCnnnTA  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "16  UgwioeJl36UMJu3HGeJ4AaABAg  QILNlRvJlfQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "17  UgzaAMSfbC9GMj_B3Bd4AaABAg  EzVIkHQWnhc  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "18  Ugzmba2nOuuX753BY9F4AaABAg  dMHWOhgzUhU  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "19  UgwAVqkauXwRBtFvRch4AaABAg  RSlqWnP-Dy8  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "20  UgxYFw4Omh2-VZ_uPoJ4AaABAg  Zcy-ND_4ydQ  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "21  Ugw6_HkS66Cd7gTiWUJ4AaABAg  aLp-6C-p-T0  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "22  UgzlNvwaPDuH-LGBffV4AaABAg  qfyynHBFOsM  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "23  UgyDIFz35EFbW6oPngJ4AaABAg  _zxPx1PQCqI  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "24  UgwXmTGwI7M7dNRuaOp4AaABAg  zOR0-nygfDE  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "25  Ugzzq9JnZy_ZI8XSXtF4AaABAg  QMUZ5HfWMRc  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "26  UgwgLsOoP63uwjzVkXF4AaABAg  EE1Y2enHrcU  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "27  UgxO-cPLG4hQGM66rAl4AaABAg  PyYgERKq25I  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "28  UgynJSMRpU8So4x2JsZ4AaABAg  CUa30M_FPhk  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "29  UgzMXcHpacJh8rFIIkN4AaABAg  9URM1_2S0ho  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "30  UgwMuQkFzq6PywxlE-d4AaABAg  C75TROiiEa0  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "31  UgyxwBZqT9GBUaHAAQ14AaABAg  u3QcbYNUgtU  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "32  UgwZyRcTVX-56o9kzgt4AaABAg  XD1ul5fpnGI  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "33  UgxuvYTItKz_7IsiLq94AaABAg  HiOtQMcI5wg  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "34  UgxHWZLY4sRR3ZdK6uR4AaABAg  pPy3sbeGNjQ  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "35  Ugyt7KO5FdfYZ3rwUuF4AaABAg  5gf2ntjVGe8  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "36  UgxHTBX_qgms7XY_3aV4AaABAg  F1ILGTXKUQM  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "37  Ugw2ZDUF4qRRMK2rZxx4AaABAg  egtF-C5WIpk  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "38  Ugz7b4cg-RCl0VhmodF4AaABAg  xzR4L_XYW3g  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "39  UgzSlFIWxMiSlsal9Kd4AaABAg  qfyynHBFOsM  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "40  Ugx_NBG2WR20D0_Dcf54AaABAg  HYD8KjPB9F8  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "41  UgyI3qISYwNH6MxPZE94AaABAg  U2v76H_B1rs  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "42  UgyF8sb9afUaWSNpb5Z4AaABAg  Z2AachB309o  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "43  Ugx-5WlLIBCpX9zO2ZJ4AaABAg  MfUzKeEKtr8  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "44  UgzLrDRONMSdolPo9tN4AaABAg  tBfIh3VQX2o  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "45  UgyyhmDjX3ZcaQ2NL3x4AaABAg  JPHS10dt_CY  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "46  UgyQfEtBtbvgrXY8OS94AaABAg  8dTpNajxaH0  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "47  UgzieBc9gpnx1igU_IR4AaABAg  uyCXLr7cgrs  UCLLw7jmFsvfIVaUFsLs8mlQ   \n",
       "48  UgzPB_FrSjz57bQdyFZ4AaABAg  8SolrjsGqzE  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "49  UgxdKlIY9TIhiTzj06B4AaABAg  wnapnTAMj68  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "\n",
       "                                         comment_text         published_at  \n",
       "0   One nice thing is that I read you can potentia...  2021-04-06 22:54:08  \n",
       "1   i want to say thank you sir! Alex The Analyst\\...  2024-06-27 06:03:18  \n",
       "2   Hmmm...  Wonder how I managed to get my commen...  2024-05-14 02:08:59  \n",
       "3   dude I don't know if you know this, but RP cam...  2023-02-02 00:15:12  \n",
       "4   Hi Alex.  Thanks a lot for this video!  One qu...  2021-04-13 11:27:40  \n",
       "5   I work at fedex and i just saw your play butto...  2023-01-30 05:59:36  \n",
       "6   It’s not worth it. But this is a google platfo...  2022-03-17 19:53:56  \n",
       "7                     Thanks for your detailed tips 👍  2021-06-10 13:52:29  \n",
       "8   This was great!! Has anyone signed up for the ...  2022-05-11 21:39:51  \n",
       "9   Additionally you need to have excellent presen...  2021-10-11 06:39:55  \n",
       "10  This is great. Thanks for clarifying with exam...  2023-11-25 11:30:31  \n",
       "11  i actually don't know you, but this video prem...  2023-02-07 13:25:02  \n",
       "12                                  you are amazing 😍  2024-07-22 23:43:52  \n",
       "13  I've been trying to import it into SSMS v19.3,...  2024-01-23 01:41:16  \n",
       "14  Hi Alex quick question how long do you think w...  2023-01-11 07:06:49  \n",
       "15  Hello all, \\nfor the part where he deleted the...  2024-06-18 11:16:12  \n",
       "16  I have a student version of Tableau, so I was ...  2023-01-21 21:13:45  \n",
       "17        Thank you for sharing this helpful thing. 💙  2023-08-22 04:35:39  \n",
       "18  Do i need to know programming to become data a...  2021-10-18 02:40:42  \n",
       "19  I tried inserting rows but I am coming up with...  2024-03-03 22:18:48  \n",
       "20  The main reason is Python would be so long to ...  2022-05-07 20:11:34  \n",
       "21  Yes true.. That has been my approach...You can...  2021-07-18 19:09:05  \n",
       "22  Hey Alex,\\nI chose to work on BigQuery as SQL....  2021-08-22 18:24:12  \n",
       "23  Hey Alex, I just wanted to say thank you for a...  2021-08-11 22:07:58  \n",
       "24  Hi, I have been trying to save the dashboard/w...  2022-01-30 01:12:55  \n",
       "25                                            AMAZING  2024-05-25 19:37:17  \n",
       "26  I encountered this error when using free plan ...  2023-03-20 02:21:54  \n",
       "27  Who wants to team up and learn? I'm just start...  2023-08-15 10:54:26  \n",
       "28  hey alex even i m trying to get the job in dat...  2021-08-23 18:06:43  \n",
       "29                I got us to 669 ;) Awesome Content!  2021-08-19 16:44:59  \n",
       "30  Hi Alex, amazing video, I’ve always been inter...  2023-02-20 14:24:32  \n",
       "31  No matter what year it is, it seems Excel is a...  2023-09-22 19:54:31  \n",
       "32   Great videos. Any discount code as of right now?  2024-02-20 07:59:42  \n",
       "33  Sir, I am very near to get my first job throug...  2022-04-21 11:51:58  \n",
       "34  Excuse the ignorance, what does scraping achieve?  2022-12-21 00:22:09  \n",
       "35  Good that you clearly pointed out that this co...  2024-03-17 17:00:05  \n",
       "36                          Thanks Luke for the video  2024-01-17 05:08:18  \n",
       "37  Why does everyone takes Space grey? And not th...  2022-07-07 21:54:33  \n",
       "38  Respected Sir\\r\\nIs the SPSS and AMOS software...  2021-07-22 03:35:47  \n",
       "39  re:grouping by continent @37:14-- even though ...  2022-01-10 02:34:45  \n",
       "40              can you do tutorial of dates in mysql  2023-11-07 13:23:34  \n",
       "41  First of all, this is a fabulous collection of...  2022-04-27 04:01:17  \n",
       "42  Jalapeños Alex! Haha thanks for this other vid...  2022-04-14 10:00:41  \n",
       "43                             4:33 there he said it.  2023-04-25 21:07:47  \n",
       "44                                             Thanks  2022-06-10 21:01:21  \n",
       "45  Do make similar videos for Quantum Computing i...  2023-02-16 01:02:12  \n",
       "46                                      Thanks a lot!  2024-08-09 13:13:46  \n",
       "47  Bard will summarize and do other math stuff no...  2023-09-29 18:55:38  \n",
       "48                                            Avacado  2022-01-19 19:25:18  \n",
       "49  Please stop the soy boy open mouth look. It’s ...  2021-03-25 20:39:30  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d63f1",
   "metadata": {},
   "source": [
    "## VADER\n",
    "VADER (Valence Aware Dictionary for sEntiment Reasoning) is a sentiment analysis tool designed specifically for social media texts. It employs a rule-based approach, leveraging a pre-defined lexicon of words and phrases along with grammatical and syntactical rules to determine the sentiment of a given text. The tool is particularly effective in handling the informal and colloquial language often found in social media posts, including the use of emoticons, acronyms, and slang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8194c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VADER sentiment intensity analyzer\n",
    "vader_sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to get sentiment scores\n",
    "def get_sentiment(text):\n",
    "    return vader_sia.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "# Apply sentiment analysis to each comment and store sentiment scores in new column \n",
    "comments_df[\"sentiment_score\"] = comments_df[\"comment_text\"].apply(get_sentiment)\n",
    "\n",
    "# Define a function to categorize the sentiment scores into positve, negative, or neutral\n",
    "def categorize_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Apply sentiment categorization to each comment and store sentiment category in new column \n",
    "comments_df[\"sentiment\"] = comments_df[\"sentiment_score\"].apply(categorize_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffc3bb41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i'm ready</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please help me</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey Alex the social  links in your channel description can't be accessible you need to fix that and you Gmail isn't there too.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The future of Binance: an exclusive interview with the CEO</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks Alex! Great series, much needed! Could you also do an end- to-end project with different data services like Synapse, ADF, Databricks and Power BI?</td>\n",
       "      <td>0.8774</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>An insider's perspective: exclusive interview with Binance's CEO on future developments</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I was just thinking of where to learn about azure and here we go .one more bootcamp from the best da teacher.in whole youtube right now🎉</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>You're the best!!!! Mr Freberg❤❤</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hello @Alex_The_Analyst and everyone,\\nPlease i really need your help to sign up on Microsoft Azure, I reside in Nigeria and my debit card is not accepted. Here is the error message \"We’re unable to validate the credit card information you provided\" Please help.🙏\\n\\nThank you.</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Where do you begin to start configuring Azure?</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Don't do it... azure sucks. As soon as you get qualified the goal posts move... not because it got better, because microsoft just like making an industry out of pointless change. Not just that... its an american company and we all know what america is now the UN has acknowledged americas goons in israel are just a bunch of naartsees... veto the bad guys and evolve :)</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I was looking for this!!!! I saw your post on LinkedIn and noticed there were more videos, are you releasing them like a whole new season on Netflix? That will be awesome 😊. As a data analyst I feel I need some exposure to all this Azure pipelines that the data engineers keep taking about, and I have almost zero knowledge of it.</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series on satistical analysis and R programming, please</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>By doing the course on Analyst Builder platform can i skip this series here? In other words is this series already covered among the course of analyst builder?</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Really appreaciting your work Alex !\\nExcited to follow the Azure Series as i already have created the account after watching the video.</td>\n",
       "      <td>0.5707</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hello alex, i just want to appreciate what you do. i've been following your channel for a while, i completed your excel, sql, power bi courses and i just recently started working for company as a junior data analyst. i just want to thank you, you helped me so much and i couldn't do this without you.  thanks to you because you changed my life, i wish you all the best.</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thank you sir! You are awesome</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I appreciate your input on this topic. I’m a big fan of your work.</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thanks 👍 for your great struggling sir 🎉❤</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>So, what's better, Alex's boot camp or the Google Data Analyst Certificate?</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                         comment_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           i'm ready   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                      Please help me   \n",
       "2                                                                                                                                                                                                                                                      Hey Alex the social  links in your channel description can't be accessible you need to fix that and you Gmail isn't there too.   \n",
       "3                                                                                                                                                                                                                                                                                                                          The future of Binance: an exclusive interview with the CEO   \n",
       "4                                                                                                                                                                                                                           Thanks Alex! Great series, much needed! Could you also do an end- to-end project with different data services like Synapse, ADF, Databricks and Power BI?   \n",
       "5                                                                                                                                                                                                                                                                                             An insider's perspective: exclusive interview with Binance's CEO on future developments   \n",
       "6                                                                                                                                                                                                                                            I was just thinking of where to learn about azure and here we go .one more bootcamp from the best da teacher.in whole youtube right now🎉   \n",
       "7                                                                                                                                                                                                                                                                                                                                                    You're the best!!!! Mr Freberg❤❤   \n",
       "8                                                                                               Hello @Alex_The_Analyst and everyone,\\nPlease i really need your help to sign up on Microsoft Azure, I reside in Nigeria and my debit card is not accepted. Here is the error message \"We’re unable to validate the credit card information you provided\" Please help.🙏\\n\\nThank you.   \n",
       "9                                                                                                                                                                                                                                                                                                                                      Where do you begin to start configuring Azure?   \n",
       "10  Don't do it... azure sucks. As soon as you get qualified the goal posts move... not because it got better, because microsoft just like making an industry out of pointless change. Not just that... its an american company and we all know what america is now the UN has acknowledged americas goons in israel are just a bunch of naartsees... veto the bad guys and evolve :)   \n",
       "11                                         I was looking for this!!!! I saw your post on LinkedIn and noticed there were more videos, are you releasing them like a whole new season on Netflix? That will be awesome 😊. As a data analyst I feel I need some exposure to all this Azure pipelines that the data engineers keep taking about, and I have almost zero knowledge of it.   \n",
       "12                                                                                                                                                                                                                                                                                                                            Series on satistical analysis and R programming, please   \n",
       "13                                                                                                                                                                                                                    By doing the course on Analyst Builder platform can i skip this series here? In other words is this series already covered among the course of analyst builder?   \n",
       "14                                                                                                                                                                                                                                           Really appreaciting your work Alex !\\nExcited to follow the Azure Series as i already have created the account after watching the video.   \n",
       "15  Hello alex, i just want to appreciate what you do. i've been following your channel for a while, i completed your excel, sql, power bi courses and i just recently started working for company as a junior data analyst. i just want to thank you, you helped me so much and i couldn't do this without you.  thanks to you because you changed my life, i wish you all the best.   \n",
       "16                                                                                                                                                                                                                                                                                                                                                     Thank you sir! You are awesome   \n",
       "17                                                                                                                                                                                                                                                                                                                 I appreciate your input on this topic. I’m a big fan of your work.   \n",
       "18                                                                                                                                                                                                                                                                                                                                          Thanks 👍 for your great struggling sir 🎉❤   \n",
       "19                                                                                                                                                                                                                                                                                                        So, what's better, Alex's boot camp or the Google Data Analyst Certificate?   \n",
       "\n",
       "    sentiment_score sentiment  \n",
       "0            0.3612  Positive  \n",
       "1            0.6124  Positive  \n",
       "2            0.0000   Neutral  \n",
       "3            0.1280  Positive  \n",
       "4            0.8774  Positive  \n",
       "5            0.1280  Positive  \n",
       "6            0.7845  Positive  \n",
       "7            0.9410  Positive  \n",
       "8            0.9072  Positive  \n",
       "9            0.0000   Neutral  \n",
       "10           0.3400  Positive  \n",
       "11           0.9296  Positive  \n",
       "12           0.3182  Positive  \n",
       "13           0.0000   Neutral  \n",
       "14           0.5707  Positive  \n",
       "15           0.9231  Positive  \n",
       "16           0.7840  Positive  \n",
       "17           0.6124  Positive  \n",
       "18           0.9022  Positive  \n",
       "19           0.4404  Positive  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows to verify the results\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "comments_df[[\"comment_text\", \"sentiment_score\", \"sentiment\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3801a5",
   "metadata": {},
   "source": [
    "## DistilBERT\n",
    "DistilBERT (Distilled BERT) is a machine learning-based model that is a smaller, faster, and more efficient version of BERT (Bidirectional Encoder Representations from Transformers). With 66 million parameters, the [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) model by Hugging Face maintains around 97% of BERT's performance while being significantly faster and lighter. Fine-tuned on the Stanford Sentiment Treebank (SST-2) dataset, it achieves 91.3% accuracy in sentiment classification, close to BERT's 92.7%. The model performs binary sentiment classification, identifying text as either positive or negative. This model is ideal for sentiment analysis tasks, such as social media monitoring, customer feedback analysis, and brand sentiment tracking, especially on devices with limited computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99083e6-e049-40f4-b239-3b32c0181e29",
   "metadata": {},
   "source": [
    "## RoBERTa \n",
    "RoBERTa (Robustly Optimized BERT Pretraining Approach) is an enhanced version of BERT, featuring 125 million parameters and improved performance due to larger datasets and optimized hyperparameters. The [twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) model by [cardiffnlp](https://huggingface.co/cardiffnlp) is trained on approximately 124 million tweets and fine-tuned using the TweetEval benchmark. Unlike DistilBERT, RoBERTa performs ternary classification, categorizing text as positive, negative, or neutral. Its ability to understand context and detect subtle sentiment cues makes it ideal for analyzing diverse and context-rich social media comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453484cb",
   "metadata": {},
   "source": [
    "# Word clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1fafe",
   "metadata": {},
   "source": [
    "Word clouds to visualize the main topics of each YouTube channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f194c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each channel\n",
    "for channel_id in channel_df[\"channel_id\"].values:\n",
    "    # Print channel name\n",
    "    print(channel_df[channel_df[\"channel_id\"]==channel_id][\"channel_name\"].values[0])\n",
    "\n",
    "    # Combine all video titles into a single string\n",
    "    text = \" \".join(videos_df[videos_df[\"channel_id\"]==channel_id][\"video_title\"])\n",
    "    \n",
    "    # Create a WordCloud object\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\", random_state=7)\n",
    "\n",
    "    # Create a word cloud of the video titles\n",
    "    wordcloud.generate(text)\n",
    "\n",
    "    # Display the word cloud \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")  # Turn off the axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ba3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_youtube_dev",
   "language": "python",
   "name": "venv_youtube_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
