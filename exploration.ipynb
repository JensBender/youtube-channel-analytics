{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41982808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install python-dotenv\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install google-api-python-client\n",
    "# !pip install mysql-connector-python\n",
    "# !pip install sqlalchemy\n",
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4344b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from googleapiclient.discovery import build\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import re\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get YouTube API key from .env \n",
    "youtube_api_key = os.getenv(\"youtube_api_key\")\n",
    "\n",
    "# Get MySQL username from .env\n",
    "mysql_user = os.getenv(\"mysql_user\")\n",
    "# Get MySQL password from .env\n",
    "mysql_password = os.getenv(\"mysql_password\")\n",
    "\n",
    "# Get AWS MySQL host from .env\n",
    "aws_mysql_host = os.getenv(\"aws_mysql_host\")\n",
    "# Get AWS MySQL username from .env\n",
    "aws_mysql_user = os.getenv(\"aws_mysql_user\")\n",
    "# Get AWS MySQL password from .env\n",
    "aws_mysql_password = os.getenv(\"aws_mysql_password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf5253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the YouTube service object\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=youtube_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b01556f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>views</th>\n",
       "      <th>videos</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>thumbnail_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>32865046</td>\n",
       "      <td>298</td>\n",
       "      <td>751000</td>\n",
       "      <td>https://yt3.ggpht.com/ytc/AIdro_l9wLnClpLKJeVm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>21499969</td>\n",
       "      <td>157</td>\n",
       "      <td>430000</td>\n",
       "      <td>https://yt3.ggpht.com/ytc/AIdro_my6YXWfudW8qM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>7493696</td>\n",
       "      <td>84</td>\n",
       "      <td>225000</td>\n",
       "      <td>https://yt3.ggpht.com/s3HLl-uzqEaqww2tkWKgjLFf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id           channel_name     views  videos  \\\n",
       "0  UC7cs8q-gJRlGwj4A8OmCmXg       Alex The Analyst  32865046     298   \n",
       "1  UCLLw7jmFsvfIVaUFsLs8mlQ          Luke Barousse  21499969     157   \n",
       "2  UCJQJAI7IjbLcpsjWdSzYz0Q  Thu Vu data analytics   7493696      84   \n",
       "\n",
       "   subscribers                                      thumbnail_url  \n",
       "0       751000  https://yt3.ggpht.com/ytc/AIdro_l9wLnClpLKJeVm...  \n",
       "1       430000  https://yt3.ggpht.com/ytc/AIdro_my6YXWfudW8qM_...  \n",
       "2       225000  https://yt3.ggpht.com/s3HLl-uzqEaqww2tkWKgjLFf...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract YouTube channel data\n",
    "\n",
    "# Select channels\n",
    "channel_names = [\"AlexTheAnalyst\", \"LukeBarousse\", \"Thuvu5\"]\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each channel\n",
    "channels_ls = []\n",
    "\n",
    "# Initialize an empty list to store uploads playlist IDs of all channels\n",
    "uploads_playlist_ids = []\n",
    "\n",
    "# Loop through each channel\n",
    "for channel_name in channel_names:\n",
    "    # Get channel data using the YouTube Channels API\n",
    "    # Note: Uses 1 out of 10.000 units from the daily usage limit \n",
    "    channel_data = youtube.channels().list(part=\"statistics,snippet,contentDetails\", forHandle=channel_name).execute()  \n",
    "\n",
    "    # Extract channel data in dictionary format\n",
    "    channel_dict = {\n",
    "        \"channel_id\": channel_data[\"items\"][0][\"id\"],\n",
    "        \"channel_name\": channel_data[\"items\"][0][\"snippet\"][\"title\"],\n",
    "        \"views\": int(channel_data[\"items\"][0][\"statistics\"][\"viewCount\"]),\n",
    "        \"videos\": int(channel_data[\"items\"][0][\"statistics\"][\"videoCount\"]),\n",
    "        \"subscribers\": int(channel_data[\"items\"][0][\"statistics\"][\"subscriberCount\"])\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Try to get channel thumbnail in maximum resolution\n",
    "        channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"maxres\"][\"url\"]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            # If maxres is not available, get high resolution\n",
    "            channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]\n",
    "        except KeyError:\n",
    "            # If high resolution is not available, get default resolution\n",
    "            channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "    \n",
    "    # Append channel data in dictionary format to the list\n",
    "    channels_ls.append(channel_dict)\n",
    "    \n",
    "    # Append uploads playlist ID to the list \n",
    "    uploads_playlist_ids.append(channel_data[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"])\n",
    "\n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "channel_df = pd.DataFrame(channels_ls) \n",
    "channel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e34385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_description</th>\n",
       "      <th>published_at</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>thumbnail_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c5ko0sedE7k</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>750k Subscriber Livestream! | Giveaways | Song...</td>\n",
       "      <td>Thank you guys so much for 750k subscribers!! ...</td>\n",
       "      <td>2024-04-18 18:35:41</td>\n",
       "      <td>PT1H23M16S</td>\n",
       "      <td>3146</td>\n",
       "      <td>204</td>\n",
       "      <td>9</td>\n",
       "      <td>https://i.ytimg.com/vi/c5ko0sedE7k/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4UltKCnnnTA</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Data Cleaning in MySQL | Full Project</td>\n",
       "      <td>Full MySQL Course: https://www.analystbuilder....</td>\n",
       "      <td>2024-04-16 12:00:05</td>\n",
       "      <td>PT51M11S</td>\n",
       "      <td>12357</td>\n",
       "      <td>542</td>\n",
       "      <td>61</td>\n",
       "      <td>https://i.ytimg.com/vi/4UltKCnnnTA/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BV5ckMNNvi4</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>How to get Promoted as a Data Analyst | Alex T...</td>\n",
       "      <td>I was promoted fairly quickly over my career a...</td>\n",
       "      <td>2024-04-09 12:00:08</td>\n",
       "      <td>PT56M14S</td>\n",
       "      <td>6367</td>\n",
       "      <td>215</td>\n",
       "      <td>70</td>\n",
       "      <td>https://i.ytimg.com/vi/BV5ckMNNvi4/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QMUZ5HfWMRc</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Triggers and Events in MySQL | Advanced MySQL ...</td>\n",
       "      <td>Full MySQL Course: https://www.analystbuilder....</td>\n",
       "      <td>2024-04-02 12:00:19</td>\n",
       "      <td>PT14M42S</td>\n",
       "      <td>6118</td>\n",
       "      <td>220</td>\n",
       "      <td>8</td>\n",
       "      <td>https://i.ytimg.com/vi/QMUZ5HfWMRc/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7b8ViCqD9JM</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>How to give up on the job search fast</td>\n",
       "      <td>💻Analyst Builder - https://www.analystbuilder....</td>\n",
       "      <td>2024-03-27 12:19:35</td>\n",
       "      <td>PT52S</td>\n",
       "      <td>6466</td>\n",
       "      <td>404</td>\n",
       "      <td>13</td>\n",
       "      <td>https://i.ytimg.com/vi/7b8ViCqD9JM/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>5LWoJAh-kww</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Data Analyst Skill Stack // How I Became A Dat...</td>\n",
       "      <td>👩🏻‍💻 My laptop and iPad for doing DS/ study 👉 ...</td>\n",
       "      <td>2021-06-16 10:16:47</td>\n",
       "      <td>PT10M35S</td>\n",
       "      <td>32964</td>\n",
       "      <td>1795</td>\n",
       "      <td>70</td>\n",
       "      <td>https://i.ytimg.com/vi/5LWoJAh-kww/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>_RzoHVWKwq4</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Effective visual note-taking on iPad + Downloa...</td>\n",
       "      <td>Hi there! In this video I’m showing you how to...</td>\n",
       "      <td>2021-06-09 06:58:21</td>\n",
       "      <td>PT8M19S</td>\n",
       "      <td>11570</td>\n",
       "      <td>396</td>\n",
       "      <td>14</td>\n",
       "      <td>https://i.ytimg.com/vi/_RzoHVWKwq4/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>hWKLO7GtpiU</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Data scientist is NOT the only SEXY job // All...</td>\n",
       "      <td>Hi there! In this video I explain different da...</td>\n",
       "      <td>2021-06-01 22:51:42</td>\n",
       "      <td>PT14M4S</td>\n",
       "      <td>8878</td>\n",
       "      <td>293</td>\n",
       "      <td>20</td>\n",
       "      <td>https://i.ytimg.com/vi/hWKLO7GtpiU/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>dBZqggW22rs</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>How I take notes on iPad Pro | Notion, Notes, ...</td>\n",
       "      <td>My note-taking system tour in Notion and tips ...</td>\n",
       "      <td>2021-05-16 22:47:12</td>\n",
       "      <td>PT9M7S</td>\n",
       "      <td>11474</td>\n",
       "      <td>277</td>\n",
       "      <td>21</td>\n",
       "      <td>https://i.ytimg.com/vi/dBZqggW22rs/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>How to stay focused and productive online with...</td>\n",
       "      <td>Hello Youtube! This is my first ever Youtube v...</td>\n",
       "      <td>2021-04-30 16:03:53</td>\n",
       "      <td>PT4M34S</td>\n",
       "      <td>4834</td>\n",
       "      <td>167</td>\n",
       "      <td>15</td>\n",
       "      <td>https://i.ytimg.com/vi/QDdqsFCIxIk/maxresdefau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                channel_id  \\\n",
       "0    c5ko0sedE7k  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "1    4UltKCnnnTA  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "2    BV5ckMNNvi4  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "3    QMUZ5HfWMRc  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "4    7b8ViCqD9JM  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "..           ...                       ...   \n",
       "535  5LWoJAh-kww  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "536  _RzoHVWKwq4  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "537  hWKLO7GtpiU  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "538  dBZqggW22rs  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "539  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "\n",
       "                                           video_title  \\\n",
       "0    750k Subscriber Livestream! | Giveaways | Song...   \n",
       "1                Data Cleaning in MySQL | Full Project   \n",
       "2    How to get Promoted as a Data Analyst | Alex T...   \n",
       "3    Triggers and Events in MySQL | Advanced MySQL ...   \n",
       "4                How to give up on the job search fast   \n",
       "..                                                 ...   \n",
       "535  Data Analyst Skill Stack // How I Became A Dat...   \n",
       "536  Effective visual note-taking on iPad + Downloa...   \n",
       "537  Data scientist is NOT the only SEXY job // All...   \n",
       "538  How I take notes on iPad Pro | Notion, Notes, ...   \n",
       "539  How to stay focused and productive online with...   \n",
       "\n",
       "                                     video_description        published_at  \\\n",
       "0    Thank you guys so much for 750k subscribers!! ... 2024-04-18 18:35:41   \n",
       "1    Full MySQL Course: https://www.analystbuilder.... 2024-04-16 12:00:05   \n",
       "2    I was promoted fairly quickly over my career a... 2024-04-09 12:00:08   \n",
       "3    Full MySQL Course: https://www.analystbuilder.... 2024-04-02 12:00:19   \n",
       "4    💻Analyst Builder - https://www.analystbuilder.... 2024-03-27 12:19:35   \n",
       "..                                                 ...                 ...   \n",
       "535  👩🏻‍💻 My laptop and iPad for doing DS/ study 👉 ... 2021-06-16 10:16:47   \n",
       "536  Hi there! In this video I’m showing you how to... 2021-06-09 06:58:21   \n",
       "537  Hi there! In this video I explain different da... 2021-06-01 22:51:42   \n",
       "538  My note-taking system tour in Notion and tips ... 2021-05-16 22:47:12   \n",
       "539  Hello Youtube! This is my first ever Youtube v... 2021-04-30 16:03:53   \n",
       "\n",
       "    video_duration  views  likes  comments  \\\n",
       "0       PT1H23M16S   3146    204         9   \n",
       "1         PT51M11S  12357    542        61   \n",
       "2         PT56M14S   6367    215        70   \n",
       "3         PT14M42S   6118    220         8   \n",
       "4            PT52S   6466    404        13   \n",
       "..             ...    ...    ...       ...   \n",
       "535       PT10M35S  32964   1795        70   \n",
       "536        PT8M19S  11570    396        14   \n",
       "537        PT14M4S   8878    293        20   \n",
       "538         PT9M7S  11474    277        21   \n",
       "539        PT4M34S   4834    167        15   \n",
       "\n",
       "                                         thumbnail_url  \n",
       "0    https://i.ytimg.com/vi/c5ko0sedE7k/maxresdefau...  \n",
       "1    https://i.ytimg.com/vi/4UltKCnnnTA/maxresdefau...  \n",
       "2    https://i.ytimg.com/vi/BV5ckMNNvi4/maxresdefau...  \n",
       "3    https://i.ytimg.com/vi/QMUZ5HfWMRc/maxresdefau...  \n",
       "4    https://i.ytimg.com/vi/7b8ViCqD9JM/maxresdefau...  \n",
       "..                                                 ...  \n",
       "535  https://i.ytimg.com/vi/5LWoJAh-kww/maxresdefau...  \n",
       "536  https://i.ytimg.com/vi/_RzoHVWKwq4/maxresdefau...  \n",
       "537  https://i.ytimg.com/vi/hWKLO7GtpiU/maxresdefau...  \n",
       "538  https://i.ytimg.com/vi/dBZqggW22rs/maxresdefau...  \n",
       "539  https://i.ytimg.com/vi/QDdqsFCIxIk/maxresdefau...  \n",
       "\n",
       "[540 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract video data\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each video\n",
    "videos_ls = []\n",
    "\n",
    "# Loop through each channel's uploads playlist\n",
    "for uploads_playlist_id in uploads_playlist_ids:\n",
    "    # Initialize next_page_token to None\n",
    "    next_page_token = None\n",
    "\n",
    "    # Loop through each video in the playlist\n",
    "    while True:\n",
    "        # Get playlist data using the YouTube PlaylistItems API \n",
    "        # Note: Each loop uses 1 out of 10.000 units from the daily usage limit (1 unit for 50 videos)\n",
    "        playlist_data = youtube.playlistItems().list(\n",
    "            part=\"snippet\", \n",
    "            playlistId=uploads_playlist_id, \n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        # Initialize an empty list to store video IDs\n",
    "        video_ids = []\n",
    "\n",
    "        # Extract video IDs from the playlist data\n",
    "        video_ids += [video_data[\"snippet\"][\"resourceId\"][\"videoId\"] for video_data in playlist_data[\"items\"]]\n",
    "\n",
    "        # Get video data using the YouTube Videos API \n",
    "        # Note: Uses 1 out of 10.000 units from the daily usage limit (1 unit for 50 videos)\n",
    "        video_data = youtube.videos().list(part=\"statistics,snippet,contentDetails\", id=video_ids).execute()    \n",
    "\n",
    "        # Loop through each video \n",
    "        for video in video_data[\"items\"]:\n",
    "            # Extract video data in dictionary format\n",
    "            video_dict = {\n",
    "                \"video_id\": video[\"id\"],\n",
    "                \"channel_id\": video[\"snippet\"][\"channelId\"],\n",
    "                \"video_title\": video[\"snippet\"][\"title\"],\n",
    "                \"video_description\": video[\"snippet\"][\"description\"],\n",
    "                \"published_at\": datetime.strptime(video[\"snippet\"][\"publishedAt\"], \"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                \"video_duration\": video[\"contentDetails\"][\"duration\"],\n",
    "                \"views\": int(video[\"statistics\"][\"viewCount\"]),\n",
    "                \"likes\": int(video[\"statistics\"][\"likeCount\"]),\n",
    "                \"comments\": int(video[\"statistics\"][\"commentCount\"])\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                # Try to get thumbnail in maximum resolution\n",
    "                video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"maxres\"][\"url\"]\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    # If maxres is not available, get high resolution\n",
    "                    video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]\n",
    "                except KeyError:\n",
    "                    # If high resolution is not available, get default resolution\n",
    "                    video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "\n",
    "            # Append video data in dictionary format to the list\n",
    "            videos_ls.append(video_dict)\n",
    "\n",
    "        # Get the next page token\n",
    "        next_page_token = playlist_data.get(\"nextPageToken\")\n",
    "\n",
    "        # Exit the loop if there are no more pages\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "        \n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "videos_df = pd.DataFrame(videos_ls)    \n",
    "videos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f293dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the YouTube video duration from ISO 8601 format (str) to seconds (int)\n",
    "def convert_iso8601_duration(duration):\n",
    "    # Regular expression to match hours, minutes, and seconds\n",
    "    time_extractor = re.compile(r'PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?')\n",
    "    # Extract hours, minutes, and seconds\n",
    "    extracted = time_extractor.match(duration)\n",
    "    if extracted:\n",
    "        hours = int(extracted.group(1)) if extracted.group(1) else 0\n",
    "        minutes = int(extracted.group(2)) if extracted.group(2) else 0\n",
    "        seconds = int(extracted.group(3)) if extracted.group(3) else 0\n",
    "        # Return total seconds\n",
    "        total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "        return total_seconds\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1037c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert video duration \n",
    "videos_df[\"video_duration\"] = videos_df[\"video_duration\"].apply(convert_iso8601_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14367996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get comments for video r9imv1z82jQ.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugx0XXl1P3K9DpU9U-94AaABAg</td>\n",
       "      <td>c5ko0sedE7k</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hello Alex, I missed your live streams , pleas...</td>\n",
       "      <td>2024-04-19 02:17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgyZBFnGTl5DZ6ngf1d4AaABAg</td>\n",
       "      <td>c5ko0sedE7k</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Congratulations, Alex.\\n\\nYou have been very i...</td>\n",
       "      <td>2024-04-18 21:58:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgxqNAeaMIlVyWkbQW94AaABAg</td>\n",
       "      <td>c5ko0sedE7k</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Way to go Alex🎉</td>\n",
       "      <td>2024-04-18 20:46:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgzMlcXgW2NynGlR1QB4AaABAg</td>\n",
       "      <td>c5ko0sedE7k</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hi Alex! Help: l purchased the bundle course$1...</td>\n",
       "      <td>2024-04-18 20:20:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugy92K5vT8yi5lNj0mh4AaABAg</td>\n",
       "      <td>c5ko0sedE7k</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>I haven't got any code 🥺😟</td>\n",
       "      <td>2024-04-18 19:59:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28038</th>\n",
       "      <td>UgykL4IfQ7CLbONTW5t4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>thank you, please i need you help!!</td>\n",
       "      <td>2022-03-07 11:10:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28039</th>\n",
       "      <td>UgzyWHk3Kx6N3sbElMJ4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Very diff but great inputs from similar topic ...</td>\n",
       "      <td>2022-02-20 00:42:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28040</th>\n",
       "      <td>Ugw1X4GuVl6jdAB8sFJ4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Replying email and control backspace was new f...</td>\n",
       "      <td>2021-08-02 15:15:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28041</th>\n",
       "      <td>UgzDqSm_tOqxIbgclvF4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Valuable insight😇</td>\n",
       "      <td>2021-07-14 10:17:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28042</th>\n",
       "      <td>Ugy9O3Xlo1_2Oqb8G-R4AaABAg</td>\n",
       "      <td>QDdqsFCIxIk</td>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>good tips for working time at home</td>\n",
       "      <td>2021-05-04 09:26:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28043 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       comment_id     video_id                channel_id  \\\n",
       "0      Ugx0XXl1P3K9DpU9U-94AaABAg  c5ko0sedE7k  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "1      UgyZBFnGTl5DZ6ngf1d4AaABAg  c5ko0sedE7k  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "2      UgxqNAeaMIlVyWkbQW94AaABAg  c5ko0sedE7k  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "3      UgzMlcXgW2NynGlR1QB4AaABAg  c5ko0sedE7k  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "4      Ugy92K5vT8yi5lNj0mh4AaABAg  c5ko0sedE7k  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "...                           ...          ...                       ...   \n",
       "28038  UgykL4IfQ7CLbONTW5t4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "28039  UgzyWHk3Kx6N3sbElMJ4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "28040  Ugw1X4GuVl6jdAB8sFJ4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "28041  UgzDqSm_tOqxIbgclvF4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "28042  Ugy9O3Xlo1_2Oqb8G-R4AaABAg  QDdqsFCIxIk  UCJQJAI7IjbLcpsjWdSzYz0Q   \n",
       "\n",
       "                                            comment_text        published_at  \n",
       "0      Hello Alex, I missed your live streams , pleas... 2024-04-19 02:17:40  \n",
       "1      Congratulations, Alex.\\n\\nYou have been very i... 2024-04-18 21:58:43  \n",
       "2                                        Way to go Alex🎉 2024-04-18 20:46:46  \n",
       "3      Hi Alex! Help: l purchased the bundle course$1... 2024-04-18 20:20:25  \n",
       "4                              I haven't got any code 🥺😟 2024-04-18 19:59:54  \n",
       "...                                                  ...                 ...  \n",
       "28038                thank you, please i need you help!! 2022-03-07 11:10:44  \n",
       "28039  Very diff but great inputs from similar topic ... 2022-02-20 00:42:23  \n",
       "28040  Replying email and control backspace was new f... 2021-08-02 15:15:34  \n",
       "28041                                  Valuable insight😇 2021-07-14 10:17:53  \n",
       "28042                 good tips for working time at home 2021-05-04 09:26:36  \n",
       "\n",
       "[28043 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract comments data\n",
    "\n",
    "# Initialize an empty list to store comments\n",
    "comments_ls = []\n",
    "\n",
    "# Loop through each video\n",
    "for video_id in videos_df[\"video_id\"].values:\n",
    "    # Initialize next_page_token to None\n",
    "    next_page_token = None\n",
    "\n",
    "    # Loop through data batches of 100 comments \n",
    "    while True:\n",
    "        try:\n",
    "            # Get data from 100 comments using the YouTube CommentThreads API \n",
    "            # Note: Each loop uses 1 out of 10.000 units from the daily usage limit (1 unit for 100 comments)\n",
    "            comments_data = youtube.commentThreads().list(\n",
    "                part=\"snippet\", \n",
    "                videoId=video_id, \n",
    "                maxResults=100,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "        # Handle error if e.g. video comments are disabled\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get comments for video {video_id}.\")\n",
    "\n",
    "        # Loop through each comment\n",
    "        for comment in comments_data[\"items\"]:\n",
    "            # Extract comment data in dictionary format\n",
    "            comment_dict = {\n",
    "                \"comment_id\": comment[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                \"video_id\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"videoId\"],\n",
    "                \"channel_id\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"channelId\"],\n",
    "                \"comment_text\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"],\n",
    "                \"published_at\": datetime.strptime(comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            }\n",
    "            # Append comment data dictionary to the list\n",
    "            comments_ls.append(comment_dict)\n",
    "\n",
    "        # Get the next page token\n",
    "        next_page_token = playlist_data.get(\"nextPageToken\")\n",
    "\n",
    "        # Exit the loop if there are no more pages\n",
    "        if next_page_token is None: \n",
    "            break\n",
    "        \n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "comments_df = pd.DataFrame(comments_ls)    \n",
    "comments_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Pandas DataFrames into MySQL tables\n",
    "\n",
    "# Connect to MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = mysql_user,\n",
    "    password = mysql_password,\n",
    "    database = \"youtube_analytics\"\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Drop existing MySQL tables \n",
    "tables_to_drop = [\"comments\", \"videos\", \"channels\"]\n",
    "for table in tables_to_drop:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "        \n",
    "try:\n",
    "    # Create an SQLAlchemy engine for interacting with the MySQL database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{mysql_user}:{mysql_password}@localhost/youtube_analytics\") \n",
    "    \n",
    "    # Load the YouTube channels DataFrame into the MySQL channels table\n",
    "    try:\n",
    "        channel_df.to_sql(\"channels\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Channels data successfully loaded into MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading channels data:\", e)\n",
    "    \n",
    "    # Load the YouTube videos DataFrame into the MySQL videos table\n",
    "    try:\n",
    "        videos_df.to_sql(\"videos\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Videos data successfully loaded into MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading videos data:\", e)\n",
    "    \n",
    "    # Load the YouTube comments DataFrame into the MySQL comments table\n",
    "    try:\n",
    "        comments_df.to_sql(\"comments\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Comments data successfully loaded into MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading comments data:\", e)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print error if exception occurs when connecting to the database \n",
    "    print(\"Error connecting to MySQL database:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection to free up resources\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Pandas DataFrames into AWS MySQL tables\n",
    "\n",
    "# Connect to AWS MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host = aws_mysql_host,\n",
    "    user = aws_mysql_user,\n",
    "    password = aws_mysql_password,\n",
    "    database = \"youtube_analytics\"\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Drop existing MySQL tables \n",
    "tables_to_drop = [\"comments\", \"videos\", \"channels\"]\n",
    "for table in tables_to_drop:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "        \n",
    "try:\n",
    "    # Create an SQLAlchemy engine for interacting with the MySQL database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{aws_mysql_user}:{aws_mysql_password}@{aws_mysql_host}/youtube_analytics\") \n",
    "    \n",
    "    # Load the YouTube channels DataFrame into the MySQL channels table\n",
    "    try:\n",
    "        channel_df.to_sql(\"channels\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Channels data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading channels data:\", e)\n",
    "    \n",
    "    # Load the YouTube videos DataFrame into the MySQL videos table\n",
    "    try:\n",
    "        videos_df.to_sql(\"videos\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Videos data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading videos data:\", e)\n",
    "    \n",
    "    # Load the YouTube comments DataFrame into the MySQL comments table\n",
    "    try:\n",
    "        comments_df.to_sql(\"comments\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Comments data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading comments data:\", e)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print error if exception occurs when connecting to the database \n",
    "    print(\"Error connecting to AWS MySQL database:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection to free up resources\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1fafe",
   "metadata": {},
   "source": [
    "Word cloud to visualize the main topics of a YouTube channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f194c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each channel\n",
    "for channel_id in channel_df[\"channel_id\"].values:\n",
    "    # Print channel name\n",
    "    print(channel_df[channel_df[\"channel_id\"]==channel_id][\"channel_name\"].values[0])\n",
    "\n",
    "    # Combine all video titles into a single string\n",
    "    text = \" \".join(videos_df[videos_df[\"channel_id\"]==channel_id][\"video_title\"])\n",
    "    \n",
    "    # Create a WordCloud object\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\", random_state=7)\n",
    "\n",
    "    # Create a word cloud of the video titles\n",
    "    wordcloud.generate(text)\n",
    "\n",
    "    # Display the word cloud \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")  # Turn off the axis\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_youtube_dev",
   "language": "python",
   "name": "venv_youtube_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
