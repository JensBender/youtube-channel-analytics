{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41982808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install python-dotenv\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install google-api-python-client\n",
    "# !pip install mysql-connector-python\n",
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4344b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7c593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get YouTube API key from .env \n",
    "youtube_api_key = os.getenv(\"youtube_api_key\")\n",
    "# Get MySQL username from .env\n",
    "mysql_user = os.getenv(\"mysql_user\")\n",
    "# Get MySQL password from .env\n",
    "mysql_password = os.getenv(\"mysql_password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdf5253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the YouTube service object\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=youtube_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b01556f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from a single YouTube channel\n",
    "channel_name = \"AlexTheAnalyst\"\n",
    "\n",
    "# Get channel data using the YouTube channels API\n",
    "# Note: Uses 1 out of 10.000 units from the daily usage limit \n",
    "channel_data = youtube.channels().list(part=\"statistics,snippet,contentDetails\", forHandle=channel_name).execute()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "520014c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>views</th>\n",
       "      <th>videos</th>\n",
       "      <th>subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>31918404</td>\n",
       "      <td>294</td>\n",
       "      <td>734000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id      channel_name     views  videos  subscribers\n",
       "0  UC7cs8q-gJRlGwj4A8OmCmXg  Alex The Analyst  31918404     294       734000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant channel data and store as pandas DataFrame\n",
    "channel_df = pd.DataFrame([{\n",
    "    \"channel_id\": channel_data[\"items\"][0][\"id\"],\n",
    "    \"channel_name\": channel_data[\"items\"][0][\"snippet\"][\"title\"],\n",
    "    \"views\": int(channel_data[\"items\"][0][\"statistics\"][\"viewCount\"]),\n",
    "    \"videos\": int(channel_data[\"items\"][0][\"statistics\"][\"videoCount\"]),\n",
    "    \"subscribers\": int(channel_data[\"items\"][0][\"statistics\"][\"subscriberCount\"])\n",
    "}])\n",
    "channel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a81d7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UU7cs8q-gJRlGwj4A8OmCmXg'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract uploads playlist ID containing all videos of the channel \n",
    "uploads_playlist_id = channel_data[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "uploads_playlist_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e34385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_description</th>\n",
       "      <th>published_at</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>thumbnail_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7b8ViCqD9JM</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>How to give up on the job search fast</td>\n",
       "      <td>ðŸ’»Analyst Builder - https://www.analystbuilder....</td>\n",
       "      <td>2024-03-27T12:19:35Z</td>\n",
       "      <td>PT52S</td>\n",
       "      <td>216</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>https://i.ytimg.com/vi/7b8ViCqD9JM/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7vnxpcqmqNQ</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Stored Procedures in MySQL | Advanced MySQL Se...</td>\n",
       "      <td>Full MySQL Course: https://www.analystbuilder....</td>\n",
       "      <td>2024-03-26T12:00:12Z</td>\n",
       "      <td>PT12M37S</td>\n",
       "      <td>1898</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>https://i.ytimg.com/vi/7vnxpcqmqNQ/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uEk07jXdKOo</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Temp Tables in MySQL | Advanced MySQL Series</td>\n",
       "      <td>Full MySQL Course: https://www.analystbuilder....</td>\n",
       "      <td>2024-03-19T12:00:56Z</td>\n",
       "      <td>PT7M46S</td>\n",
       "      <td>4487</td>\n",
       "      <td>156</td>\n",
       "      <td>8</td>\n",
       "      <td>https://i.ytimg.com/vi/uEk07jXdKOo/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC7uvOqcUTs</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>CTEs in MySQL | Advanced MySQL Series</td>\n",
       "      <td>Full MySQL Course: https://www.analystbuilder....</td>\n",
       "      <td>2024-03-12T12:00:23Z</td>\n",
       "      <td>PT10M31S</td>\n",
       "      <td>7359</td>\n",
       "      <td>225</td>\n",
       "      <td>15</td>\n",
       "      <td>https://i.ytimg.com/vi/UC7uvOqcUTs/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1KEbiqRWOkA</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>7 Mistakes to Avoid During Your Data Analyst J...</td>\n",
       "      <td>When I was a Hiring Managers I saw a lot of pe...</td>\n",
       "      <td>2024-03-05T13:00:01Z</td>\n",
       "      <td>PT11M54S</td>\n",
       "      <td>15282</td>\n",
       "      <td>572</td>\n",
       "      <td>49</td>\n",
       "      <td>https://i.ytimg.com/vi/1KEbiqRWOkA/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>4rfr6A3lO-Y</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Data Analyst Resume | Reviewing My Resume! | F...</td>\n",
       "      <td>Data Analyst Resume | Reviewing My Resume! | F...</td>\n",
       "      <td>2020-01-30T14:07:55Z</td>\n",
       "      <td>PT7M33S</td>\n",
       "      <td>69864</td>\n",
       "      <td>1640</td>\n",
       "      <td>64</td>\n",
       "      <td>https://i.ytimg.com/vi/4rfr6A3lO-Y/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>OTq2NRy_AGs</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Working at a Big Company Vs Small Company | To...</td>\n",
       "      <td>Working at a Big Company Vs Small Company | To...</td>\n",
       "      <td>2020-01-25T16:38:39Z</td>\n",
       "      <td>PT5M50S</td>\n",
       "      <td>14942</td>\n",
       "      <td>404</td>\n",
       "      <td>22</td>\n",
       "      <td>https://i.ytimg.com/vi/OTq2NRy_AGs/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>ya28cb3zFGE</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Data Analyst Salary | 100k with No Experience</td>\n",
       "      <td>Data Analyst Salary | 100k with No Experience ...</td>\n",
       "      <td>2020-01-23T03:16:09Z</td>\n",
       "      <td>PT5M3S</td>\n",
       "      <td>63554</td>\n",
       "      <td>2172</td>\n",
       "      <td>227</td>\n",
       "      <td>https://i.ytimg.com/vi/ya28cb3zFGE/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Hsi2BG0SOiQ</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Truth About Big Companies | Told by a Fortune ...</td>\n",
       "      <td>Truth About Big Companies // There are a ton o...</td>\n",
       "      <td>2020-01-21T03:52:15Z</td>\n",
       "      <td>PT5M45S</td>\n",
       "      <td>8637</td>\n",
       "      <td>316</td>\n",
       "      <td>18</td>\n",
       "      <td>https://i.ytimg.com/vi/Hsi2BG0SOiQ/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>6lQzbk6_OTw</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Top 3 Data Analyst Skills in 2020</td>\n",
       "      <td>Top 3 Data Analyst Skills in 2020 // There are...</td>\n",
       "      <td>2020-01-17T14:31:39Z</td>\n",
       "      <td>PT2M40S</td>\n",
       "      <td>28509</td>\n",
       "      <td>1379</td>\n",
       "      <td>138</td>\n",
       "      <td>https://i.ytimg.com/vi/6lQzbk6_OTw/maxresdefau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                channel_id  \\\n",
       "0    7b8ViCqD9JM  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "1    7vnxpcqmqNQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "2    uEk07jXdKOo  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "3    UC7uvOqcUTs  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "4    1KEbiqRWOkA  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "..           ...                       ...   \n",
       "289  4rfr6A3lO-Y  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "290  OTq2NRy_AGs  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "291  ya28cb3zFGE  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "292  Hsi2BG0SOiQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "293  6lQzbk6_OTw  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "\n",
       "                                           video_title  \\\n",
       "0                How to give up on the job search fast   \n",
       "1    Stored Procedures in MySQL | Advanced MySQL Se...   \n",
       "2         Temp Tables in MySQL | Advanced MySQL Series   \n",
       "3                CTEs in MySQL | Advanced MySQL Series   \n",
       "4    7 Mistakes to Avoid During Your Data Analyst J...   \n",
       "..                                                 ...   \n",
       "289  Data Analyst Resume | Reviewing My Resume! | F...   \n",
       "290  Working at a Big Company Vs Small Company | To...   \n",
       "291      Data Analyst Salary | 100k with No Experience   \n",
       "292  Truth About Big Companies | Told by a Fortune ...   \n",
       "293                  Top 3 Data Analyst Skills in 2020   \n",
       "\n",
       "                                     video_description          published_at  \\\n",
       "0    ðŸ’»Analyst Builder - https://www.analystbuilder....  2024-03-27T12:19:35Z   \n",
       "1    Full MySQL Course: https://www.analystbuilder....  2024-03-26T12:00:12Z   \n",
       "2    Full MySQL Course: https://www.analystbuilder....  2024-03-19T12:00:56Z   \n",
       "3    Full MySQL Course: https://www.analystbuilder....  2024-03-12T12:00:23Z   \n",
       "4    When I was a Hiring Managers I saw a lot of pe...  2024-03-05T13:00:01Z   \n",
       "..                                                 ...                   ...   \n",
       "289  Data Analyst Resume | Reviewing My Resume! | F...  2020-01-30T14:07:55Z   \n",
       "290  Working at a Big Company Vs Small Company | To...  2020-01-25T16:38:39Z   \n",
       "291  Data Analyst Salary | 100k with No Experience ...  2020-01-23T03:16:09Z   \n",
       "292  Truth About Big Companies // There are a ton o...  2020-01-21T03:52:15Z   \n",
       "293  Top 3 Data Analyst Skills in 2020 // There are...  2020-01-17T14:31:39Z   \n",
       "\n",
       "    video_duration  views likes comments  \\\n",
       "0            PT52S    216    44        2   \n",
       "1         PT12M37S   1898    90        7   \n",
       "2          PT7M46S   4487   156        8   \n",
       "3         PT10M31S   7359   225       15   \n",
       "4         PT11M54S  15282   572       49   \n",
       "..             ...    ...   ...      ...   \n",
       "289        PT7M33S  69864  1640       64   \n",
       "290        PT5M50S  14942   404       22   \n",
       "291         PT5M3S  63554  2172      227   \n",
       "292        PT5M45S   8637   316       18   \n",
       "293        PT2M40S  28509  1379      138   \n",
       "\n",
       "                                         thumbnail_url  \n",
       "0    https://i.ytimg.com/vi/7b8ViCqD9JM/maxresdefau...  \n",
       "1    https://i.ytimg.com/vi/7vnxpcqmqNQ/maxresdefau...  \n",
       "2    https://i.ytimg.com/vi/uEk07jXdKOo/maxresdefau...  \n",
       "3    https://i.ytimg.com/vi/UC7uvOqcUTs/maxresdefau...  \n",
       "4    https://i.ytimg.com/vi/1KEbiqRWOkA/maxresdefau...  \n",
       "..                                                 ...  \n",
       "289     https://i.ytimg.com/vi/4rfr6A3lO-Y/default.jpg  \n",
       "290     https://i.ytimg.com/vi/OTq2NRy_AGs/default.jpg  \n",
       "291     https://i.ytimg.com/vi/ya28cb3zFGE/default.jpg  \n",
       "292     https://i.ytimg.com/vi/Hsi2BG0SOiQ/default.jpg  \n",
       "293  https://i.ytimg.com/vi/6lQzbk6_OTw/maxresdefau...  \n",
       "\n",
       "[294 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract video data\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each video\n",
    "videos_ls = []\n",
    "\n",
    "# Initialize next_page_token to None\n",
    "next_page_token = None\n",
    "\n",
    "# Loop through each video in the uploads playlist\n",
    "while True:\n",
    "    # Get playlist data using the YouTube PlaylistItems API \n",
    "    # Note: Each loop uses 1 out of 10.000 units from the daily usage limit (1 unit for 50 videos)\n",
    "    playlist_data = youtube.playlistItems().list(\n",
    "        part=\"snippet\", \n",
    "        playlistId=uploads_playlist_id, \n",
    "        maxResults=50,\n",
    "        pageToken=next_page_token\n",
    "    ).execute()\n",
    "    \n",
    "    # Initialize an empty list to store video IDs\n",
    "    video_ids = []\n",
    "\n",
    "    # Extract video IDs from the playlist data\n",
    "    video_ids += [video_data[\"snippet\"][\"resourceId\"][\"videoId\"] for video_data in playlist_data[\"items\"]]\n",
    "    \n",
    "    # Get video data using the YouTube Videos API \n",
    "    # Note: Uses 1 out of 10.000 units from the daily usage limit (1 unit per 50 videos)\n",
    "    video_data = youtube.videos().list(part=\"statistics,snippet,contentDetails\", id=video_ids).execute()    \n",
    "\n",
    "    # Loop through each video \n",
    "    for video in video_data[\"items\"]:\n",
    "        # Extract relevant data \n",
    "        video_dict = {\n",
    "            \"video_id\": video[\"id\"],\n",
    "            \"channel_id\": video[\"snippet\"][\"channelId\"],\n",
    "            \"video_title\": video[\"snippet\"][\"title\"],\n",
    "            \"video_description\": video[\"snippet\"][\"description\"],\n",
    "            \"published_at\": video[\"snippet\"][\"publishedAt\"],\n",
    "            \"video_duration\": video[\"contentDetails\"][\"duration\"],\n",
    "            \"views\": video[\"statistics\"][\"viewCount\"],\n",
    "            \"likes\": video[\"statistics\"][\"likeCount\"],\n",
    "            \"comments\": video[\"statistics\"][\"commentCount\"],\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Try to get thumbnail in maximum resolution\n",
    "            video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"maxres\"][\"url\"]\n",
    "        except KeyError:\n",
    "            # If maxres is not available, get default resolution\n",
    "            video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "        \n",
    "        # Append video data dictionary to the list\n",
    "        videos_ls.append(video_dict)\n",
    " \n",
    "    # Get the next page token\n",
    "    next_page_token = playlist_data.get(\"nextPageToken\")\n",
    "    \n",
    "    # Exit the loop if there are no more pages\n",
    "    if next_page_token is None:\n",
    "        break\n",
    "        \n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "videos_df = pd.DataFrame(videos_ls)    \n",
    "videos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1340c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgxWFbxtmtXNGcjbKyB4AaABAg</td>\n",
       "      <td>7vnxpcqmqNQ</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Work out the problems that God has assigned you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugy_W5U-LBIwrC0T_Bt4AaABAg</td>\n",
       "      <td>7vnxpcqmqNQ</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Does that require write permissions?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugw8qi8vhP3rxHiv0wx4AaABAg</td>\n",
       "      <td>7vnxpcqmqNQ</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgxMQae8IV5kV8uTHCB4AaABAg</td>\n",
       "      <td>7vnxpcqmqNQ</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Dear Alex\\r\\nMy name is Molwedi Ramoeletsi Aug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugwpbyi1L1r2gXzeatJ4AaABAg</td>\n",
       "      <td>7vnxpcqmqNQ</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Pls do video on creation of views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16017</th>\n",
       "      <td>UgztX5Zp0jjsOBtRqdp4AaABAg</td>\n",
       "      <td>6lQzbk6_OTw</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hey Alex, what do you think about COGNOS?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16018</th>\n",
       "      <td>Ugx5i3bb5-5V8zNge_x4AaABAg</td>\n",
       "      <td>6lQzbk6_OTw</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hi Alex,\\nfound your channel on Reddit and am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16019</th>\n",
       "      <td>Ugz9os89TlxWUGtj0zR4AaABAg</td>\n",
       "      <td>6lQzbk6_OTw</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Great video, Alex! I definitely agree that Exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16020</th>\n",
       "      <td>UgxgUXmGkengAMwgAGt4AaABAg</td>\n",
       "      <td>6lQzbk6_OTw</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Hey Alex, great video, just went through all o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>UgziAI6ScfiJ4IhDg4J4AaABAg</td>\n",
       "      <td>6lQzbk6_OTw</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Your thoughts on Google Sheets compared to Excel?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16022 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       comment_id     video_id                channel_id  \\\n",
       "0      UgxWFbxtmtXNGcjbKyB4AaABAg  7vnxpcqmqNQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "1      Ugy_W5U-LBIwrC0T_Bt4AaABAg  7vnxpcqmqNQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "2      Ugw8qi8vhP3rxHiv0wx4AaABAg  7vnxpcqmqNQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "3      UgxMQae8IV5kV8uTHCB4AaABAg  7vnxpcqmqNQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "4      Ugwpbyi1L1r2gXzeatJ4AaABAg  7vnxpcqmqNQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "...                           ...          ...                       ...   \n",
       "16017  UgztX5Zp0jjsOBtRqdp4AaABAg  6lQzbk6_OTw  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "16018  Ugx5i3bb5-5V8zNge_x4AaABAg  6lQzbk6_OTw  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "16019  Ugz9os89TlxWUGtj0zR4AaABAg  6lQzbk6_OTw  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "16020  UgxgUXmGkengAMwgAGt4AaABAg  6lQzbk6_OTw  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "16021  UgziAI6ScfiJ4IhDg4J4AaABAg  6lQzbk6_OTw  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "\n",
       "                                            comment_text  \n",
       "0        Work out the problems that God has assigned you  \n",
       "1                   Does that require write permissions?  \n",
       "2                                              excellent  \n",
       "3      Dear Alex\\r\\nMy name is Molwedi Ramoeletsi Aug...  \n",
       "4                      Pls do video on creation of views  \n",
       "...                                                  ...  \n",
       "16017          Hey Alex, what do you think about COGNOS?  \n",
       "16018  Hi Alex,\\nfound your channel on Reddit and am ...  \n",
       "16019  Great video, Alex! I definitely agree that Exc...  \n",
       "16020  Hey Alex, great video, just went through all o...  \n",
       "16021  Your thoughts on Google Sheets compared to Excel?  \n",
       "\n",
       "[16022 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract comments data\n",
    "\n",
    "# Initialize an empty list to store comments\n",
    "comments_ls = []\n",
    "\n",
    "# Loop through each video\n",
    "for video_id in video_ids:\n",
    "    # Initialize next_page_token to None\n",
    "    next_page_token = None\n",
    "\n",
    "    # Loop through data batches of 100 comments \n",
    "    while True:\n",
    "        # Get data from 100 comments using the YouTube CommentThreads API \n",
    "        # Note: Each loop uses 1 out of 10.000 units from the daily usage limit (1 unit for 100 comments)\n",
    "        comments_data = youtube.commentThreads().list(\n",
    "            part=\"snippet\", \n",
    "            videoId=video_id, \n",
    "            maxResults=100,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        # Loop through each comment\n",
    "        for comment in comments_data[\"items\"]:\n",
    "            # Extract comment data in dictionary format\n",
    "            comment_dict = {\n",
    "                \"comment_id\": comment[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                \"video_id\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"videoId\"],\n",
    "                \"channel_id\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"channelId\"],\n",
    "                \"comment_text\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"]\n",
    "            }\n",
    "            # Append comment data dictionary to the list\n",
    "            comments_ls.append(comment_dict)\n",
    "\n",
    "        # Get the next page token\n",
    "        next_page_token = playlist_data.get(\"nextPageToken\")\n",
    "\n",
    "        # Exit the loop if there are no more pages\n",
    "        if next_page_token is None: \n",
    "            break\n",
    "        \n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "comments_df = pd.DataFrame(comments_ls)    \n",
    "comments_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9952063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to MySQL database.\n"
     ]
    }
   ],
   "source": [
    "# Load data into a MySQL database\n",
    "\n",
    "# Connect to MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = mysql_user,\n",
    "    password = mysql_password,\n",
    "    database = \"youtube_analytics\"\n",
    ")\n",
    "\n",
    "# Create a cursor object for executing SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Save pandas DataFrame to MySQL table\n",
    "try:\n",
    "    # Create a SQLAlchemy engine for interacting with the MySQL database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{mysql_user}:{mysql_password}@localhost/youtube_analytics\")\n",
    "    # Save the YouTube channels DataFrame to a MySQL table \n",
    "    channel_df.to_sql(\"channels\", con=engine, if_exists=\"replace\", index=False)\n",
    "    # Save the YouTube videos DataFrame to a MySQL table \n",
    "    videos_df.to_sql(\"videos\", con=engine, if_exists=\"replace\", index=False)\n",
    "    # Save the YouTube comments DataFrame to a MySQL table \n",
    "    videos_df.to_sql(\"comments\", con=engine, if_exists=\"replace\", index=False)\n",
    "    # Print a success message\n",
    "    print(\"DataFrame successfully saved to MySQL database.\")\n",
    "except Exception as e:\n",
    "    # Print an error message if any exception occurs\n",
    "    print(\"Error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection to free up resources\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_youtube_dev",
   "language": "python",
   "name": "venv_youtube_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
