{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41982808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install python-dotenv\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install google-api-python-client\n",
    "# !pip install mysql-connector-python\n",
    "# !pip install sqlalchemy\n",
    "# !pip install wordcloud\n",
    "# !pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4344b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from googleapiclient.discovery import build\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get YouTube API key from .env \n",
    "youtube_api_key = os.getenv(\"youtube_api_key\")\n",
    "\n",
    "# Get local MySQL server username from .env\n",
    "mysql_user = os.getenv(\"mysql_user\")\n",
    "# Get local MySQL server password from .env\n",
    "mysql_password = os.getenv(\"mysql_password\")\n",
    "\n",
    "# Get AWS MySQL server username from .env\n",
    "aws_mysql_user = os.getenv(\"aws_mysql_user\")\n",
    "# Get AWS MySQL server password from .env\n",
    "aws_mysql_password = os.getenv(\"aws_mysql_password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83362ef",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the YouTube service object\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=youtube_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01556f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract YouTube channel data\n",
    "\n",
    "# Select channels\n",
    "channel_names = [\"AlexTheAnalyst\", \"LukeBarousse\", \"Thuvu5\"]\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each channel\n",
    "channels_ls = []\n",
    "\n",
    "# Initialize an empty list to store uploads playlist IDs of all channels\n",
    "uploads_playlist_ids = []\n",
    "\n",
    "# Loop through each channel\n",
    "for channel_name in channel_names:\n",
    "    # Get channel data using the YouTube Channels API\n",
    "    # Note: Uses 1 out of 10.000 units from the daily usage limit \n",
    "    channel_data = youtube.channels().list(part=\"statistics,snippet,contentDetails\", forHandle=channel_name).execute()  \n",
    "\n",
    "    # Extract channel data in dictionary format\n",
    "    channel_dict = {\n",
    "        \"channel_id\": channel_data[\"items\"][0][\"id\"],\n",
    "        \"channel_name\": channel_data[\"items\"][0][\"snippet\"][\"title\"],\n",
    "        \"views\": int(channel_data[\"items\"][0][\"statistics\"][\"viewCount\"]),\n",
    "        \"videos\": int(channel_data[\"items\"][0][\"statistics\"][\"videoCount\"]),\n",
    "        \"subscribers\": int(channel_data[\"items\"][0][\"statistics\"][\"subscriberCount\"])\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Try to get channel thumbnail in maximum resolution\n",
    "        channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"maxres\"][\"url\"]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            # If maxres is not available, get high resolution\n",
    "            channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]\n",
    "        except KeyError:\n",
    "            # If high resolution is not available, get default resolution\n",
    "            channel_dict[\"thumbnail_url\"] = channel_data[\"items\"][0][\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "    \n",
    "    # Append channel data in dictionary format to the list\n",
    "    channels_ls.append(channel_dict)\n",
    "    \n",
    "    # Append uploads playlist ID to the list \n",
    "    uploads_playlist_ids.append(channel_data[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"])\n",
    "\n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "channel_df = pd.DataFrame(channels_ls) \n",
    "channel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract video data\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each video\n",
    "videos_ls = []\n",
    "\n",
    "# Loop through each channel's uploads playlist\n",
    "for uploads_playlist_id in uploads_playlist_ids:\n",
    "    # Initialize next_page_token to None\n",
    "    next_page_token = None\n",
    "\n",
    "    # Loop through each video in the playlist\n",
    "    while True:\n",
    "        # Get playlist data using the YouTube PlaylistItems API \n",
    "        # Note: Each loop uses 1 out of 10.000 units from the daily usage limit (1 unit for 50 videos)\n",
    "        playlist_data = youtube.playlistItems().list(\n",
    "            part=\"snippet\", \n",
    "            playlistId=uploads_playlist_id, \n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        # Initialize an empty list to store video IDs\n",
    "        video_ids = []\n",
    "\n",
    "        # Extract video IDs from the playlist data\n",
    "        video_ids += [video_data[\"snippet\"][\"resourceId\"][\"videoId\"] for video_data in playlist_data[\"items\"]]\n",
    "\n",
    "        # Get video data using the YouTube Videos API \n",
    "        # Note: Uses 1 out of 10.000 units from the daily usage limit (1 unit for 50 videos)\n",
    "        video_data = youtube.videos().list(part=\"statistics,snippet,contentDetails\", id=video_ids).execute()    \n",
    "\n",
    "        # Loop through each video \n",
    "        for video in video_data[\"items\"]:\n",
    "            # Extract video data in dictionary format\n",
    "            video_dict = {\n",
    "                \"video_id\": video[\"id\"],\n",
    "                \"channel_id\": video[\"snippet\"][\"channelId\"],\n",
    "                \"video_title\": video[\"snippet\"][\"title\"],\n",
    "                \"video_description\": video[\"snippet\"][\"description\"],\n",
    "                \"published_at\": datetime.strptime(video[\"snippet\"][\"publishedAt\"], \"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                \"video_duration\": video[\"contentDetails\"][\"duration\"],\n",
    "                \"views\": int(video[\"statistics\"][\"viewCount\"]),\n",
    "                \"likes\": int(video[\"statistics\"][\"likeCount\"]),\n",
    "                \"comments\": int(video[\"statistics\"][\"commentCount\"])\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                # Try to get thumbnail in maximum resolution\n",
    "                video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"maxres\"][\"url\"]\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    # If maxres is not available, get high resolution\n",
    "                    video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]\n",
    "                except KeyError:\n",
    "                    # If high resolution is not available, get default resolution\n",
    "                    video_dict[\"thumbnail_url\"] = video[\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "\n",
    "            # Append video data in dictionary format to the list\n",
    "            videos_ls.append(video_dict)\n",
    "\n",
    "        # Get the next page token\n",
    "        next_page_token = playlist_data.get(\"nextPageToken\")\n",
    "\n",
    "        # Exit the loop if there are no more pages\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "        \n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "videos_df = pd.DataFrame(videos_ls)    \n",
    "videos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14367996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract comments data\n",
    "\n",
    "# Initialize an empty list to store comments\n",
    "comments_ls = []\n",
    "\n",
    "# Loop through each video\n",
    "for video_id in videos_df[\"video_id\"].values:\n",
    "    # Initialize next_page_token to None\n",
    "    next_page_token = None\n",
    "\n",
    "    # Loop through data batches of 100 comments \n",
    "    while True:\n",
    "        try:\n",
    "            # Get data from 100 comments using the YouTube CommentThreads API \n",
    "            # Note: Each loop uses 1 out of 10.000 units from the daily usage limit (1 unit for 100 comments)\n",
    "            comments_data = youtube.commentThreads().list(\n",
    "                part=\"snippet\", \n",
    "                videoId=video_id, \n",
    "                maxResults=100,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "        # Handle error if e.g. video comments are disabled\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get comments for video {video_id}.\")\n",
    "\n",
    "        # Loop through each comment\n",
    "        for comment in comments_data[\"items\"]:\n",
    "            # Extract comment data in dictionary format\n",
    "            comment_dict = {\n",
    "                \"comment_id\": comment[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                \"video_id\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"videoId\"],\n",
    "                \"channel_id\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"channelId\"],\n",
    "                \"comment_text\": comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"],\n",
    "                \"published_at\": datetime.strptime(comment[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            }\n",
    "            # Append comment data dictionary to the list\n",
    "            comments_ls.append(comment_dict)\n",
    "\n",
    "        # Get the next page token\n",
    "        next_page_token = comments_data.get(\"nextPageToken\")\n",
    "\n",
    "        # Exit the loop if there are no more pages\n",
    "        if next_page_token is None: \n",
    "            break\n",
    "        \n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "comments_df = pd.DataFrame(comments_ls)    \n",
    "comments_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182313c6",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the YouTube video duration from ISO 8601 format (str) to seconds (int)\n",
    "def convert_iso8601_duration(duration):\n",
    "    # Regular expression to match hours, minutes, and seconds\n",
    "    time_extractor = re.compile(r'PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?')\n",
    "    # Extract hours, minutes, and seconds\n",
    "    extracted = time_extractor.match(duration)\n",
    "    if extracted:\n",
    "        hours = int(extracted.group(1)) if extracted.group(1) else 0\n",
    "        minutes = int(extracted.group(2)) if extracted.group(2) else 0\n",
    "        seconds = int(extracted.group(3)) if extracted.group(3) else 0\n",
    "        # Return total seconds\n",
    "        total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "        return total_seconds\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1037c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert video duration in pandas DataFrame\n",
    "videos_df[\"video_duration\"] = videos_df[\"video_duration\"].apply(convert_iso8601_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a313e62",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Pandas DataFrames into local MySQL tables\n",
    "\n",
    "# Connect to local MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    port = 3306,\n",
    "    user = mysql_user,\n",
    "    password = mysql_password,\n",
    "    database = \"youtube_analytics\"\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Drop existing MySQL tables \n",
    "tables_to_drop = [\"comments\", \"videos\", \"channels\"]\n",
    "for table in tables_to_drop:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "        \n",
    "try:\n",
    "    # Create an SQLAlchemy engine for interacting with the MySQL database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{mysql_user}:{mysql_password}@localhost:3306/youtube_analytics\") \n",
    "    \n",
    "    # Load the YouTube channels DataFrame into the MySQL channels table\n",
    "    try:\n",
    "        channel_df.to_sql(\"channels\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Channels data successfully loaded into local MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading channels data:\", e)\n",
    "    \n",
    "    # Load the YouTube videos DataFrame into the MySQL videos table\n",
    "    try:\n",
    "        videos_df.to_sql(\"videos\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Videos data successfully loaded into local MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading videos data:\", e)\n",
    "    \n",
    "    # Load the YouTube comments DataFrame into the MySQL comments table\n",
    "    try:\n",
    "        comments_df.to_sql(\"comments\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Comments data successfully loaded into local MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading comments data:\", e)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print error if exception occurs when connecting to the database \n",
    "    print(\"Error connecting to local MySQL database:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection to free up resources\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Pandas DataFrames into AWS MySQL tables\n",
    "# Note: Make sure to establish an SSH tunnel via PuTTY to connect to the AWS RDS MySQL server through an EC2 instance\n",
    "\n",
    "# Connect to AWS MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    port = 3308,\n",
    "    user = aws_mysql_user,\n",
    "    password = aws_mysql_password,\n",
    "    database = \"youtube_analytics\"\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Drop existing MySQL tables \n",
    "tables_to_drop = [\"comments\", \"videos\", \"channels\"]\n",
    "for table in tables_to_drop:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "        \n",
    "try:\n",
    "    # Create an SQLAlchemy engine for interacting with the MySQL database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{aws_mysql_user}:{aws_mysql_password}@localhost:3308/youtube_analytics\") \n",
    "    \n",
    "    # Load the YouTube channels DataFrame into the MySQL channels table\n",
    "    try:\n",
    "        channel_df.to_sql(\"channels\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Channels data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading channels data:\", e)\n",
    "    \n",
    "    # Load the YouTube videos DataFrame into the MySQL videos table\n",
    "    try:\n",
    "        videos_df.to_sql(\"videos\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Videos data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading videos data:\", e)\n",
    "    \n",
    "    # Load the YouTube comments DataFrame into the MySQL comments table\n",
    "    try:\n",
    "        comments_df.to_sql(\"comments\", con=engine, if_exists=\"replace\", index=False)\n",
    "        print(\"Comments data successfully loaded into AWS MySQL database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading comments data:\", e)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print error if exception occurs when connecting to the database \n",
    "    print(\"Error connecting to AWS MySQL database:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection to free up resources\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453484cb",
   "metadata": {},
   "source": [
    "# Word clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1fafe",
   "metadata": {},
   "source": [
    "Word clouds to visualize the main topics of each YouTube channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f194c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each channel\n",
    "for channel_id in channel_df[\"channel_id\"].values:\n",
    "    # Print channel name\n",
    "    print(channel_df[channel_df[\"channel_id\"]==channel_id][\"channel_name\"].values[0])\n",
    "\n",
    "    # Combine all video titles into a single string\n",
    "    text = \" \".join(videos_df[videos_df[\"channel_id\"]==channel_id][\"video_title\"])\n",
    "    \n",
    "    # Create a WordCloud object\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\", random_state=7)\n",
    "\n",
    "    # Create a word cloud of the video titles\n",
    "    wordcloud.generate(text)\n",
    "\n",
    "    # Display the word cloud \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")  # Turn off the axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ba3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_youtube_dev",
   "language": "python",
   "name": "venv_youtube_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
